{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Custom Researcher Workflow\n",
    "This notebook demonstrates how to create a custom workflow using the `AgentWorkflow` class.\n",
    "\n",
    "This example extract contents from 3 urls, extract insights from the contents, review the insights, and provide a detailed report based on the insights.\n",
    "- \"https://www.anthropic.com/engineering/building-effective-agents\",\n",
    "- \"https://www.ibm.com/think/topics/agentic-workflows\",\n",
    "- \"https://aws.amazon.com/blogs/hpc/building-an-ai-simulation-assistant-with-agentic-workflows/\""
   ],
   "id": "610eee6901924b70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "f496435e825ee359"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:17:16.239801Z",
     "start_time": "2025-03-24T05:17:15.402155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from typing import Any, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from saw.core.model_interface import amodel_call\n",
    "from saw.workflow import AgentWorkflow\n",
    "from saw.workflows.utils import aapply_functions"
   ],
   "id": "feeae8f5f139d526",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:17:16.248555Z",
     "start_time": "2025-03-24T05:17:16.243584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables\n",
    "load_dotenv(\"../docker/.env\")"
   ],
   "id": "8834d7f0780fb8cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define Custom Researcher Function\n",
    "Define a custom function that will be used by the `AgentWorkflow` to research content.\n"
   ],
   "id": "a812979ba18f619d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:17:16.307652Z",
     "start_time": "2025-03-24T05:17:16.305218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def add_title(content: str, title: str) -> str:\n",
    "    \"\"\"Add a title to the top of the content.\n",
    "\n",
    "    Args:\n",
    "        content (str): The content to which the title will be added.\n",
    "        title (str): The title to add.\n",
    "\n",
    "    Returns:\n",
    "        str: The content with the title added at the top.\n",
    "    \"\"\"\n",
    "    return f\"{title}\\n\\n{content}\"\n",
    "\n",
    "\n",
    "async def fetch_content(url: str) -> str:\n",
    "    \"\"\"Fetch content from a given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to fetch content from.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the URL\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup.get_text()"
   ],
   "id": "d043d1dd9f4657c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:17:16.361348Z",
     "start_time": "2025-03-24T05:17:16.351510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def custom_researcher(researcher: Dict[str, Any], principal_researcher: Dict[str, Any], tech_lead: Dict[str, Any]) -> tuple:\n",
    "    \"\"\"Custom Researcher Function.\n",
    "\n",
    "    Args:\n",
    "        researcher (Dict[str, Any]): Dictionary containing details for the researcher role.\n",
    "        principal_researcher (Dict[str, Any]): Dictionary containing details for the principal researcher role.\n",
    "        tech_lead (Dict[str, Any]): Dictionary containing details for the tech lead role.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The results of the custom researcher functions.\n",
    "    \"\"\"\n",
    "    # Using the aapply_functions function to apply the fetch_content function\n",
    "    contents = await asyncio.gather(\n",
    "        *[aapply_functions(prompt=url, functions=researcher[\"functions\"])\n",
    "          for url in researcher[\"params\"]['urls']]\n",
    "    )\n",
    "\n",
    "    print(f\"Contents ({type(contents)}): {contents}\")\n",
    "\n",
    "    insights = []\n",
    "    for content in contents:\n",
    "        print(f\"Extracting insights from: {content}\")\n",
    "        insight = await amodel_call(\n",
    "            prompt=f\"{researcher['prompt']}\\n{content}\",\n",
    "            system_prompt=researcher['system_prompt'],\n",
    "            provider=researcher['provider'],\n",
    "            model=researcher['model']\n",
    "        )\n",
    "        insights.append(insight)\n",
    "\n",
    "    print(f\"Insights: {insights}\")\n",
    "\n",
    "    principal_researcher_approval = await amodel_call(\n",
    "        prompt=f\"{principal_researcher['prompt']}\\n{insights}\",\n",
    "        system_prompt=principal_researcher['system_prompt'],\n",
    "        provider=principal_researcher['provider'],\n",
    "        model=principal_researcher['model']\n",
    "    )\n",
    "\n",
    "    if (principal_researcher_approval and\n",
    "            \"more details\" in principal_researcher_approval.lower()):\n",
    "        insights = []\n",
    "        for content in contents:\n",
    "            insight = await amodel_call(\n",
    "                prompt=f\"{researcher['prompt']}\\n{content}\",\n",
    "                system_prompt=researcher['system_prompt'],\n",
    "                provider=researcher['provider'],\n",
    "                model=researcher['model']\n",
    "            )\n",
    "            insights.append(insight)\n",
    "\n",
    "    # Directly using the add_title function to add a title to the pr_report\n",
    "    pr_report = await principal_researcher['functions'][0](\n",
    "        title=principal_researcher['params']['title'],\n",
    "        content=principal_researcher_approval\n",
    "    )\n",
    "    print(f\"Principal Researcher Approval: {pr_report}\")\n",
    "\n",
    "    tech_lead_report = await amodel_call(\n",
    "        prompt=f\"{tech_lead['prompt']}\\n{insights}\",\n",
    "        system_prompt=tech_lead['system_prompt'],\n",
    "        provider=tech_lead['provider'],\n",
    "        model=tech_lead['model']\n",
    "    )\n",
    "\n",
    "    # Directly using the add_title function to add a title to the pr_report\n",
    "    tl_report = await tech_lead['functions'][0](\n",
    "        title=tech_lead['params']['title'],\n",
    "        content=tech_lead_report\n",
    "    )\n",
    "    print(f\"Tech Lead Report: {tl_report}\")\n",
    "\n",
    "    return insights, pr_report, tl_report"
   ],
   "id": "facea5249f5f247a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize Agent Workflow",
   "id": "fb8bd0e53c9ee72d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:17:16.407140Z",
     "start_time": "2025-03-24T05:17:16.404730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the `AgentWorkflow` with the custom researcher function.\n",
    "agent = AgentWorkflow(operation=\"custom\", custom_workflow=custom_researcher)"
   ],
   "id": "c67a28e56f50ce83",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:17:16.456957Z",
     "start_time": "2025-03-24T05:17:16.453382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define dictionaries for each role\n",
    "researcher = {\n",
    "    \"prompt\": \"Research on agents and agentic workflows.\",\n",
    "    \"system_prompt\": \"You are a researcher.\",\n",
    "    \"functions\": [fetch_content],\n",
    "    \"provider\": \"google\",\n",
    "    \"model\": \"gemini-2.0-flash\",\n",
    "    \"params\": {\n",
    "        \"urls\": [\n",
    "            \"https://www.anthropic.com/engineering/building-effective-agents\",\n",
    "            \"https://www.ibm.com/think/topics/agentic-workflows\",\n",
    "            \"https://aws.amazon.com/blogs/hpc/building-an-ai-simulation-assistant-with-agentic-workflows/\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "principal_researcher = {\n",
    "    \"prompt\": \"Analyze the key findings from the research on agents and agentic workflows.\",\n",
    "    \"system_prompt\": \"You are a principal researcher.\",\n",
    "    \"functions\": [add_title],\n",
    "    \"model\": \"deepseek-r1:1.5b\",\n",
    "    \"provider\": \"ollama\",\n",
    "    \"params\": {\n",
    "        \"title\": \"Principal Researcher Report\"\n",
    "    }\n",
    "}\n",
    "\n",
    "tech_lead = {\n",
    "    \"prompt\": \"Write a detailed report based on the key findings from the research on \"\n",
    "              \"agents and agentic workflows.\",\n",
    "    \"system_prompt\": \"You are a tech lead.\",\n",
    "    \"functions\": [add_title],\n",
    "    \"model\": \"gemini-2.0-flash\",\n",
    "    \"provider\": \"google\",\n",
    "    \"params\": {\n",
    "        \"title\": \"Tech Lead Report\"\n",
    "    }\n",
    "}"
   ],
   "id": "6a9580ef6f3d77a6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:18:45.825102Z",
     "start_time": "2025-03-24T05:17:16.517416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Execute the workflow\n",
    "insights, principal_researcher_report, tech_lead_report = await agent.execute(\n",
    "    researcher=researcher,\n",
    "    principal_researcher=principal_researcher,\n",
    "    tech_lead=tech_lead,\n",
    "    async_mode=True\n",
    ")"
   ],
   "id": "e1ac9b6c4f941c62",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Arguments: {'researcher': {'prompt': 'Research on agents and agentic workflows.', 'system_prompt': 'You are a researcher.', 'functions': [<function fetch_content at 0x7673e1f13ec0>], 'provider': 'google', 'model': 'gemini-2.0-flash', 'params': {'urls': ['https://www.anthropic.com/engineering/building-effective-agents', 'https://www.ibm.com/think/topics/agentic-workflows', 'https://aws.amazon.com/blogs/hpc/building-an-ai-simulation-assistant-with-agentic-workflows/']}}, 'principal_researcher': {'prompt': 'Analyze the key findings from the research on agents and agentic workflows.', 'system_prompt': 'You are a principal researcher.', 'functions': [<function add_title at 0x7673e1f13e20>], 'model': 'deepseek-r1:1.5b', 'provider': 'ollama', 'params': {'title': 'Principal Researcher Report'}}, 'tech_lead': {'prompt': 'Write a detailed report based on the key findings from the research on agents and agentic workflows.', 'system_prompt': 'You are a tech lead.', 'functions': [<function add_title at 0x7673e1f13e20>], 'model': 'gemini-2.0-flash', 'provider': 'google', 'params': {'title': 'Tech Lead Report'}}}\n",
      "Contents (<class 'list'>): ['Just a moment...Enable JavaScript and cookies to continue', '\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat are Agentic Workflows? | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are agentic workflows?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n                                    IT automation\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    7 March 2025\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Authors\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCole Stryker\\n\\nEditorial Lead, AI Models, Gather\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnna Gutowska\\n\\nAI Engineer, Developer Advocate\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are agentic workflows?\\r\\n    \\n\\n\\n\\nAgentic workflows are AI-driven processes where autonomous AI agents make decisions, take actions and coordinate tasks with minimal human intervention. These workflows leverage core components of intelligent agents such as reasoning, planning and tool use to execute complex tasks efficiently. Traditional automation such as robotic process automation (RPA), follow predefined rules and design patterns. This approach can be sufficient for repetitive tasks that follow a standard structure. Agentic workflows are dynamic, offering more flexibility by adapting to real-time data and unexpected conditions. AI Agentic workflows approach complex problems in a multistep, iterative way, enabling AI agents to break down business processes, adapt dynamically and refine their actions over time.\\nBy enabling generative AI to handle intricate workflows, organizations benefit from improved operational efficiency, scalability and informed decision-making. As we continue to see advancements in machine learning and natural language processing (NLP), AI technology is becoming more common in industries seeking to automate and optimize processes while reducing reliance on human oversight. The impacts of evolving AI models not only affect software development but also industries such as healthcare, finance, human resources and much more.\\xa0\\xa0\\n\\n\\n\\r\\n        How do agentic workflows work?\\r\\n    \\n\\n\\n\\nImagine a company has an IT support chatbot that follows a rule-based automation system. When an employee reports an issue (for example, \"My wifi isn’t working\"), the chatbot runs through static decision trees and provides predefined responses. If the problem isn’t resolved, the chatbot simply escalates to human support. This approach is efficient for basic, well-defined issues but struggles with complex, multistep troubleshooting that requires adaptability.\\nWith an agentic workflow, the IT assistant approaches troubleshooting as a multistep, iterative process. If an employee reports a wifi issue, the agent follows a dynamic step-by-step process for breaking down the workflow:\\nUnderstanding the problem: The AI agent gathers detailed information from the employee, asking clarifying questions like, \"Are other devices connected to the network?\" or \"Did this start after a recent update?\"Executing diagnostic steps: Based on the user’s responses, the AI selects and runs different problem-solving steps. It might ping the router, check network logs or suggest specific settings changes, retrieving and summarizing this information for the user.\\nAdaptive tool use: If the AI detects a server-side issue, it can call an internal monitoring tool API to check for outages. If the issue is device-specific, it can retrieve driver update suggestions or run a script to reset network settings.\\nIterating based on results: If an action doesn’t resolve the problem, the AI adjusts its approach dynamically. It might cross-check related issues, reattempt diagnostics or suggest a different solution instead of just escalating immediately.\\nFinalizing and learning: If the issue is fixed, the AI logs the solution for future cases, improving its troubleshooting efficiency over time. If unresolved, it escalates with a detailed report, saving IT staff time by summarizing attempted fixes.\\n\\n\\n\\n\\r\\n        Components of agentic workflows\\r\\n    \\n\\n\\n\\nThe core components of agentic workflows consist of:\\xa0\\nAI agents - In artificial intelligence (AI), a workflow is not agentic if it does not consist of an AI agent. An AI agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.Large language models (LLMs) - At the core of AI agents are large language models. LLMs are crucial for processing and generating natural language. The adjustment of LLM parameters like temperature will also result in varying output quality.\\n\\nTools - For an LLM to acquire information beyond the data used in training the model, we must provide tools. Examples of commonly used tools include external datasets, web searches and application programming interfaces (APIs). We can use tools to tailor an AI agent to specific use cases beyond routine tasks.\\n\\nFeedback mechanisms - Feedback mechanisms such as a human-in-the-loop (HITL) or even other agents can be valuable in facilitating the AI agent’s decision-making process and steering the agent output.\\xa0\\n\\nPrompt engineering - Agentic workflow performance is heavily dependent on the quality of provided prompts. Prompt engineering helps generative AI models better comprehend and respond to a wide range of queries, from the simple to the highly technical. Common prompt engineering techniques include chain of thought (CoT), one-shot, zero-shot and self-reflection.\\n\\nMultiagent collaboration - Communication and distributed problem-solving within multiagent systems (MASs) are key for complex use cases. Each agent within a MAS can be designated a set of tools, algorithms and a domain of “expertise” so that agents are not all relearning the same information. Instead, agents are sharing their learned information with the rest of the MAS. \\xa0\\n\\nIntegrations - To streamline existing processes, agentic workflows need to be integrated with the existing infrastructure. This synergy is dependent on the requirements and goals of the agentic workflow. Data integration, the process of consolidating data into a central database for the agent to access, is often the first step. Other forms of integrations include agent frameworks such as LangChain, LangGraph, crewAI and IBM’s BeeAI. These agent orchestration frameworks can serve as providers for achieving greater scale and performance. The integration of context-specific tools is also key to achieving relevant outputs. \\xa0\\n\\n\\n\\n\\n\\r\\n        The impact of agentic workflows\\r\\n    \\n\\n\\n\\nA personal anecdote from Andrew Ng, a leader in AI, highlights the adaptability of agentic workflows. Andrew recalls his demonstration of building AI agents, in which one of the many AI tools, a web search API, failed. The AI system was able to quickly handle the dependency failure by using an available Wikipedia search tool instead. The system completed the task and remained adaptable to the changing environment. The lessening need for human oversight might allow for our effort to be spent less on mundane, repetitive tasks and more on intricate work requiring human intelligence. \\xa0\\nAndrew also explains that agentic workflows are meaningful not only for task execution but also for training the next generation of LLMs. In traditional, nonagentic workflows, using the output of one LLM to train another has not been found to lead to effective results. However, using an agentic workflow that produces high-quality data leads to useful training. \\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            Top Strategic Technology Trends for 2025: Agentic AI\\n        \\nDownload this Gartner research to learn the potential opportunities and risks of agentic AI for IT leaders and learn how to prepare for this next wave of AI innovation.\\r\\n\\r\\n\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Resources\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            News\\n        \\n\\n            IBM’s answer to governing AI Agents: Automation and Evaluation with watsonx.governance\\n        \\nIBM announces how watsonx.governance enhances AI oversight, providing safer and more transparent AI deployment.\\n\\nRead the news\\n\\n\\n\\n\\n\\n\\n            Video\\n        \\n\\n            Reimagine business productivity with AI agents and assistants\\n        \\nLearn how AI agents and AI assistants can work together to achieve new levels of productivity.\\n\\nWatch now\\n\\n\\n\\n\\n\\n\\n            Podcast\\n        \\n\\n            The future of agents, AI energy consumption, Anthropic\\'s computer use and Google watermarking AI-generated text\\n        \\nStay ahead of the curve with our AI experts on this episode of Mixture of Experts as they dive deep into the future of AI agents and more.\\r\\n\\n\\nListen now\\n\\n\\n\\n\\n\\n\\n            Demo\\n        \\n\\n            Try watsonx Orchestrate\\n        \\nExplore how generative AI assistants can lighten your workload and improve productivity.\\n\\nStart the demo\\n\\n\\n\\n\\n\\n\\n            Podcast\\n        \\n\\n            How AI agents will reinvent productivity\\n        \\nLearn ways to use AI to be more creative, efficient and start adapting to a future that involves working closely with AI agents.\\n\\nListen now\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            Omdia Report Empowered Intelligence: The Impact of AI Agents\\n        \\nDiscover how you can unlock the full potential of Gen AI with AI agents.\\r\\n\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            Is your organization ready to leverage genAI?\\n        \\nExplore this IDC Spotlight report to discover how you can unlock the full potential of your business data with GenAI.\\r\\n\\r\\n\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n            Case study\\n        \\n\\n            How Comparus is using a \"banking assistant\"\\n        \\nComparus used solutions from IBM watsonx™ AI and impressively demonstrated the potential of Conversational banking as a new interaction model.\\n\\nRead the case study\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\n\\n     \\n    Related solutions\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    IBM watsonx Orchestrate\\xa0\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nStreamline your workflows and reclaim your day with watsonx Orchestrate’s automation technology.\\n\\n\\n\\n\\nExplore watsonx Orchestrate\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    IBM AI agent solutions\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nBuild the future of your business with AI solutions that you can trust.\\n\\n\\n\\nExplore AI agent solutions\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    IBM AI consulting services\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nIBM Consulting AI services help reimagine how businesses work with AI for transformation.\\n\\n\\n\\nExplore artificial intelligence services\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nWhether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered.\\n\\n\\n\\n\\n\\nExplore watsonx Orchestrate\\n\\n\\n\\nExplore watsonx.ai\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', \"\\n\\n\\n\\n\\nBuilding an AI simulation assistant with agentic workflows | AWS HPC Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Skip to Main Content\\n\\n\\n\\n\\n\\nClick here to return to Amazon Web Services homepage\\n\\n\\n\\nAbout AWS\\nContact Us\\n Support \\xa0 \\n       \\n\\n \\n English \\xa0 \\n       \\n\\n \\n My Account \\xa0 \\n       \\n\\n \\n\\n\\n\\n\\n Sign In\\n\\n\\n  Create an AWS Account \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAmazon Q\\nProducts\\nSolutions\\nPricing\\nDocumentation\\nLearn\\nPartner Network\\nAWS Marketplace\\nCustomer Enablement\\nEvents\\nExplore More \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Close \\n\\n\\n\\nعربي\\nBahasa Indonesia\\nDeutsch\\nEnglish\\nEspañol\\nFrançais\\nItaliano\\nPortuguês\\n\\n\\n\\n\\nTiếng Việt\\nTürkçe\\nΡусский\\nไทย\\n日本語\\n한국어\\n中文 (简体)\\n中文 (繁體)\\n\\n\\n\\n\\n\\n Close \\n\\nMy Profile\\nSign out of AWS Builder ID\\nAWS Management Console\\nAccount Settings\\nBilling & Cost Management\\nSecurity Credentials\\nAWS Personal Health Dashboard\\n\\n\\n\\n Close \\n\\nSupport Center\\nExpert Help\\nKnowledge Center\\nAWS Support Overview\\nAWS re:Post\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nClick here to return to Amazon Web Services homepage\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n  Get Started for Free \\n\\n\\n  Contact Us \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Products \\n Solutions \\n Pricing \\n Introduction to AWS \\n Getting Started \\n Documentation \\n Training and Certification \\n Developer Center \\n Customer Success \\n Partner Network \\n AWS Marketplace \\n Support \\n AWS re:Post \\n Log into Console \\n Download the Mobile App \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n AWS Blog Home\\n Blogs\\xa0 \\n Editions\\xa0 \\n\\n\\n\\n\\n\\n Close \\n\\n\\n\\n Architecture\\n AWS Cloud Operations\\n AWS for Games\\n AWS Insights\\n AWS Marketplace\\n AWS News\\n AWS Partner Network\\n AWS Smart Business\\n Big Data\\n Business Intelligence\\n Business Productivity\\n Cloud Enterprise Strategy\\n Cloud Financial Management\\n Compute\\n Contact Center\\n Containers\\n Database\\n Desktop & Application Streaming\\n Developer Tools\\n DevOps & Developer Productivity\\n Front-End Web & Mobile\\n\\n\\n\\n\\n HPC\\n IBM and Red Hat\\n Industries\\n Integration & Automation\\n Internet of Things\\n Machine Learning\\n Media\\n Messaging & Targeting\\n Microsoft Workloads on AWS\\n Migration and Modernization\\n .NET on AWS\\n Networking & Content Delivery\\n Open Source\\n Public Sector\\n Quantum Computing\\n Robotics\\n SAP\\n Security\\n Spatial Computing\\n Startups\\n Storage\\n Supply Chain & Logistics\\n Training & Certification\\n\\n\\n\\n\\n\\n Close \\n\\n中国版\\n日本版\\n한국 에디션\\n기술 블로그\\nEdisi Bahasa Indonesia\\nAWS Thai Blog\\nÉdition Française\\nDeutsche Edition\\nEdição em Português\\nEdición en Español\\nВерсия на русском\\nTürkçe Sürüm\\n\\n\\n\\n\\n\\n\\nAWS HPC Blog\\n\\n\\n\\nBuilding an AI simulation assistant with agentic workflows\\n\\nby Sam Bydlon\\non 28 MAY 2024\\nin AWS Batch, Compute, High Performance Computing\\nPermalink\\n Share\\n\\n\\n  \\n  \\n  \\n  \\n\\n\\n\\n\\n\\nSimulations have become indispensable tools which enable organizations to predict outcomes, evaluate risks, and make informed decisions. Simulations provide valuable insights that drive strategic decision-making – running the gamut from supply chain optimization to exploration of design alternatives for products and processes.\\nBut running and analyzing simulations can be a time-consuming task because it requires specialized teams of data scientists, analysts, and subject matter experts. In the manufacturing sector, these experts are in high demand to model and optimize complex production processes. This regularly leads to backlogs and delays in obtaining critical insights. In the healthcare industry, specialized teams of epidemiologists and statisticians run the simulations for infectious disease modeling that public health officials need to make decisions. The limited bandwidth of these specialists creates bottlenecks and inefficiencies that impact the ability to rapidly respond to emerging health crises in a data-driven manner.\\nIn this post, we’ll examine an generative AI-based “Simulation Assistant” demo application built using LangChain Agents and Anthropic’s recently released Claude V3 large language model (LLM) on Amazon Bedrock.\\nBy leveraging the latest advancements in LLMs and AWS, we’ll show you how to streamline and democratize your simulation workflows using a scalable and serverless architecture for an application with a chatbot-style interface. This will allow users to launch and interact with simulations using natural language prompts.\\nHow does this help experts?\\nThe Simulation Assistant demo offers a blueprint for providing significant value to organizations in two key ways. It:\\n\\nDemocratizes simulation-driven problem solving: While regulated industries may still require certified personnel for final sign-off, this solution demonstrates a way to democratize simulation use beyond specialist teams. By enabling knowledgeable personnel across functions, such as analysts, managers, and decision-makers, to launch and analyze simulations under the guidance of experts, organizations can increase the utilization of simulation capabilities and free up the bandwidth of their simulation experts.\\nEnhances efficiency for simulation experts: Allowing a wider user-base to run routine simulations lets experts focus on high value tasks like performance tuning or building new simulations. Streamlined, automated workflows accessible through a single chatbot interface improves productivity, standardizes processes, enables knowledge sharing, and increases result reliability.\\n\\nWhether you’re a business analyst, product manager, researcher, or a simulation expert, this demonstration offers an intuitive and efficient way to harness the power of simulations by leveraging the capabilities of generative AI through Amazon Bedrock and the scalability of AWS – driving innovation and operational excellence across diverse industries.\\nSolution overview\\n\\n\\nFigure 1 – Architectural diagram for Simulation Assistant application. A containerized Streamlit web app is deployed via a load-balanced AWS Fargate service. The web app instantiates an LLM-based agent with access to seven tools. The retriever tool provides RAG capabilities using Amazon Kendra. Others tools enable the agent to perform a custom mathematical transform, invoke a simple inflation simulation executed using AWS Lambda, invoke a set of containerized investment portfolio simulations using AWS Batch that store results in an Amazon DynamoDB table, and analyze a batch of simulation results by generating plots.\\n\\nFigure 1 depicts the architecture of the Simulation Assistant application. A web application, built using Streamlit, serves as the user interface. Streamlit is an open-source Python library that allows you to create interactive web applications for machine learning and data science use cases. We’ve containerized this app using Docker and stored it in an Amazon Elastic Container Registry (ECR) repository.\\nThe containerized web application is deployed as a load-balanced AWS Fargate Service within an Amazon Elastic Container Service (ECS) cluster. AWS Fargate is a serverless compute engine that allows you to run containers without managing servers or clusters. By using Fargate, the Simulation Assistant application can scale its compute resources up or down automatically based on the incoming traffic, ensuring optimal performance and cost-efficiency.\\nThe web application is fronted by an Application Load Balancer (ALB). The ALB distributes incoming traffic across multiple targets, like Fargate tasks, in a balanced manner. This load balancing mechanism ensures that user requests are efficiently handled, even during periods of high traffic, by dynamically routing requests to available container instances.\\nLife cycle of a request\\nWhen a user accesses the Simulation Assistant application, their request is received by the ALB, which then forwards the request to one of the healthy Fargate tasks running the Streamlit web application. This serverless deployment approach, combined with the load-balancing capabilities of the ALB, provides a highly available and scalable architecture for the Simulation Assistant, allowing it to handle varying levels of user traffic without the need for manually provisioning and managing servers.\\nThe Streamlit web application acts as the central hub, orchestrating the interaction between different AWS services to enable seamless simulation capabilities for users. Within the Streamlit app, we’ve used Amazon Bedrock to process user queries by leveraging state-of-the-art language models. Bedrock is a fully-managed service that makes these art foundation models from both Amazon and leading AI startups available via a unified API, while abstracting away complex model management.\\nFor simple simulations, like price inflation scenarios, the Streamlit app integrates with AWS Lambda functions. These serverless functions can encapsulate lightweight simulation logic, allowing for efficient execution and scalability without the need for provisioning and managing dedicated servers.\\nAdditionally, we’re also leveraging Amazon Kendra, an intelligent search service, to enable retrieval augmented generation (RAG). Amazon Kendra indexes and searches through documents stored in an Amazon S3 bucket, acting as a source repository. This integration empowers the application to provide relevant information from existing documents, enhancing the simulation capabilities and enabling more informed decision-making.\\nFor more computationally intensive simulations, like running sets of investment portfolio simulations in a Monte Carlo-style manner, the Simulation Assistant uses AWS Batch. AWS Batch is a fully managed batch processing service that efficiently runs batch computing workloads across AWS resources. The Simulation Assistant submits jobs to AWS Batch, which then dynamically provisions the compute resources needed to run them in parallel, enabling faster execution times and scalability.\\nOnce the simulations are complete, the results are stored in an Amazon DynamoDB database, a fully managed NoSQL database service. DynamoDB provides fast and predictable performance with seamless scalability, making it well-suited for storing and retrieving simulation data efficiently. Furthermore, the application integrates with Amazon EventBridge, a serverless event bus service. When a simulation batch is finished, EventBridge triggers a notification, which is sent to the user via email using Amazon Simple Notification Service (SNS). This notification system keeps users informed about the completion of their simulation requests, allowing them to promptly access and analyze the results.\\nLLM-based “agents” with “tools”\\nThe Streamlit web application houses the logic of the key technological concept underlying the Simulation Assistant application, the enablement of what is called “agentic behavior” of an LLM. The precise definition of an LLM agent is elusive, because the field is relatively new and rapidly evolving. But the general idea is to augment the capabilities of LLMs by enabling the models to break down tasks into individual steps, make plans, and take actions including the use of tools to solve specific tasks, and even work together as a team of multiple agents that can collaborate and influence each other.\\nOne design pattern for enabling agentic behavior of is called “Tool Use”, in which an LLM is taught (through prompt engineering or fine-tuning) how to trigger pieces of additional software, wrapped in a standardized form like a function call. These additional pieces of software are called “tools”. The Simulation Assistant employs tools to augment the behavior of an underlying foundation model. In our demo, the underlying foundation model is Claude V3 Sonnet.\\nTools help LLMs solve problems that are not reliably solved by direct generation using the underlying transformer network. LLMs are demonstrating incredible ability at solving problems and performing mathematical reasoning – try asking Claude V3 Sonnet to “simulate the price of milk over the next 20 years with a dynamic inflation rate where the mean is 4% and standard deviation 2%”. But their ability to simulate more complex systems like financial markets or the spread of wildfires is still (for now) best left to trusted simulation codes. By introducing tools that can execute those trusted codes and instructing the LLM on how and when tools should be used, LLMs can gain profound new abilities.\\nThere are many possibilities for what tools can be and do, and the application of tools and agentic behavior in general is a concept that will have wide ranging uses cases far beyond simulation. Tools can help LLMs to perform web searches, query a database, or schedule a meeting using your calendar system, just to name a few options.\\nHow we applied agents and tools\\nThe Simulation Assistant instantiates a LangChain agent, based on Claude V3 Sonnet. LangChain is an open-source framework for building applications with LLMs. With LangChain Agents and Tools, developers can create powerful generative AI-based applications that leverage LLM agentic behavior and integrate with existing systems and workflows.\\nThere are several kinds of agents that can be constructed with LangChain, but not all agent types support tools with multiple inputs. Since simulations often require users to specify an array of input parameters to define the system mechanics to be simulated, we’ll want to choose an agent type that supports multi-input tools and can be used in concert with Amazon Bedrock. The Simulation Assistant demo uses a structured chat agent, which satisfies both of these requirements.\\nBuilding the Simulation Assistant involved addressing several key technical challenges:\\n\\nDesigning and implementing an agent-tool architecture: To create an effective agent-tool system, careful design of the tool interfaces and integration with the LangChain agent framework was required. We handled multi-input tools by defining structured input schemas. We enabled communication between the LLM and the tools using LangChain’s tool abstraction layer.\\nPrompt engineering for agentic behavior: Crafting prompts that guide the LLM to exhibit desired agentic behavior was an iterative process. The approach involved exploring the capabilities and limitations of Claude V3 Sonnet, designing prompts that promoted appropriate tool selection and usage, and refining the prompts based on performance in test scenarios.\\nScaling and managing simulation workloads: To handle computationally intensive simulations, we designed a scalable architecture using AWS Batch for running simulation jobs. This allowed us to efficiently manage compute resources and reliably execute simulations with varying workloads.\\nInterpreting and visualizing simulation results: To help users interpret and visualize simulation outputs, we developed tools that process and summarize simulation data, and integrated visualizations within Simulation Assistant.\\n\\nWe gave the Simulation Assistant agent access to seven tools, including ones designed to perform a custom mathematical transform defined within the Streamlit application, perform simple inflation simulations housed in an AWS Lambda function, launch Monte Carlo-style simulation ensembles via AWS Batch to mimic an investment portfolio and visualize results, and to perform RAG over an internal database of documents.\\nThese are simple examples, showing how tools can be built to handle some common elements of simulation workflows. But tools can do a lot more: they can also be designed to prepare configuration files, trigger pre- or post-processing jobs on related data – or even call other specialized LLMs that are able to interpret and summarize the results of simulations.\\nA sample workflow\\nWhen a user enters a natural language query into Simulation Assistant like, “run a set of 100 investment simulations starting at $10,000, with cash flow of $250, for 50 steps,” we pass the query to Amazon Bedrock inside a prompt specifically engineered to work well in an agent-tool setting. You can find examples of polished prompts you can use at the LangChain Hub – including prompts that work well with structured chat agents.\\nBehind the scenes, the agentic LLM breaks down the request into steps, decides whether each step can be completed with “bare hands” (i.e. without tools), or whether one of its tools can be used to complete the step. For our example request, the agentic LLM determines that it needs to use a tool that allows it to run batches of investment portfolio simulations, performs the entity extraction of the key parameters like cash flow, and uses these parameters to trigger an AWS Batch job to run the simulations. It does this completely independently.\\nThe agent then responds to the user telling them they’ll receive an email when the simulations are complete and provides some helpful information that can be used to analyze the simulation results.\\nFigure 2 is a graphical depiction of this process.\\n\\n\\nFigure 2 – Workflow of an LLM-based agent with tools for batch simulation execution. User requests are formatted into prompts by the application and sent to the LLM, which decomposes the request, selects and triggers the appropriate tool with extracted parameters (run_batch_simulations tool with simulation inputs). Tool results are returned to the LLM for generating a final response displayed to the user, including information for accessing and analyzing simulation outputs.\\n\\nFor a deeper look into how we used these tools and to see the Simulation Assistant demo in action (including the batch simulation query described above) you can check out the video demo below. This will walk you through some potential interactions with the application, and shows the LLM-based agent interacting with various tools representing different aspects of a simulation workflow. You’ll see the agent list the available tools and provide instructions on how to use them when prompted.\\n\\nFigure 3 – A video showing the Simulation Assistant demo in action. Click to play.\\nThe core portion of the demo involves the user asking the agent to run a set of 100 investment portfolio simulations with specific parameters like starting amount, cash flow, and number of steps. The agent interprets this natural language query, extracts the necessary parameters, and triggers an AWS Batch job to execute the simulations in parallel. Once the simulations complete, the agent retrieves the results from a database and visualizes them using another tool.\\nAdditionally, the video contrasts the agent’s capabilities with a standard LLM’s response to the same query, so you can see the enhanced abilities provided by the agent-tool architecture. You’ll also notice the agent breaking down a complex problem into steps and leveraging multiple tools in different orders to solve it, demonstrating the flexibility of the approach.\\nFuture Work\\nWhile the Simulation Assistant demo achieves a lot, we want to extend the demo in the future to tackle some more technical challenges:\\n\\nIntegrating with existing simulation codebases: A key goal of ours is to integrate existing simulation codebases as tools within the agent-tool architecture. This will require a deep understanding of the codebases and, in some cases, modifying them to fit the tool interface requirements. For example, to integrate OpenFOAM (a popular open-source computational fluid dynamics software) as a tool, the approach would involve wrapping OpenFOAM’s solver and utility executables as Python functions, defining input and output schemas, and potentially modifying the codebase to enable programmatic execution and data exchange.\\nEnsuring simulation reproducibility and traceability: We’d like to enable comprehensive reproducibility and traceability of the simulation runs by implementing logging mechanisms that track input parameters, intermediate steps, and provide detailed documentation for each simulation execution.\\nEstablishing guardrails: Guardrails and safeguards are crucial to ensure the secure and responsible use of the simulation framework. This may involve setting limits on compute resources, enforcing access controls, and implementing validation checks to prevent potential misuse or unintended consequences. Additionally, ethical considerations should be considered, like ensuring privacy and data protection, avoiding biases, and promoting transparency in the simulation processes.\\n\\nConclusion\\nThis post introduces an AWS-native Simulation Assistant demo that we hope will provide inspiration, and a blueprint, for organizations looking to leverage generative AI and other cutting-edge techniques like agentic LLM behavior to help their businesses.\\nThe demo shows the potential of these technologies for revolutionizing simulation workflows across various industries. Using LangChain Agents, Amazon Bedrock, and the scalability of AWS services, the Simulation Assistant demo can offer a glimpse into a future where simulations might be more accessible and interactive. We hope this will let organizations unlock new insights and drive better decision-making.\\nThe application of agentic LLM frameworks extend far beyond simulations, and the concept of tools can be applied to a countless number of domains or workflows. By enabling LLMs to interact with external systems, perform computations, and trigger actions, organizations can augment their existing processes in this way, fostering innovation and operational excellence.\\nSolutions like this can also pave the way for new paradigms in human-machine collaboration, amplifying human capabilities and accelerating the pace of discovery.\\nIf your organization is interested in exploring how to implement these techniques in concert with your workflows, we encourage you to reach out to your AWS account team, or send an email to ask-hpc@amazon.com.\\n\\n\\n\\n\\n         TAGS: \\n        AWS Batch, HPC, Machine Learning, ML, simulations\\n\\n\\n\\n\\n\\nSam Bydlon\\nDr. Sam Bydlon is a Specialist Solutions Architect with the Advanced Compute, Emerging Technologies team at AWS. Sam received his Ph.D. in Geophysics from Stanford University in 2018 and has 12 years of experience developing and utilizing simulations in research science and financial services. In his spare time, Sam enjoys camping, waterfalls, and camping near waterfalls.\\n\\n\\n\\n\\n\\n\\n\\n\\n Resources\\n\\n\\nHPC on AWS Overview\\nHPC Tech Shorts Video Series\\nHPC Community Site\\nAWS Quantum Technologies Blog\\nAWS ParallelCluster\\nAWS Batch\\nNICE DCV\\nElastic Fabric Adapter\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Follow\\n\\n\\n\\xa0Twitter\\n\\xa0Facebook\\n\\xa0LinkedIn\\n\\xa0Twitch\\n\\xa0Email Updates\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  Sign In to the Console \\n\\n Learn About AWS\\n\\nWhat Is AWS?\\nWhat Is Cloud Computing?\\nAWS Accessibility\\nAWS Inclusion, Diversity & Equity\\nWhat Is DevOps?\\nWhat Is a Container?\\nWhat Is a Data Lake?\\nWhat is Artificial Intelligence (AI)?\\nWhat is Generative AI?\\nWhat is Machine Learning (ML)?\\nAWS Cloud Security\\nWhat's New\\nBlogs\\nPress Releases\\n\\n\\n\\n Resources for AWS\\n\\nGetting Started\\nTraining and Certification\\nAWS Solutions Library\\nArchitecture Center\\nProduct and Technical FAQs\\nAnalyst Reports\\nAWS Partners\\n\\n\\n\\n Developers on AWS\\n\\nDeveloper Center\\nSDKs & Tools\\n.NET on AWS\\nPython on AWS\\nJava on AWS\\nPHP on AWS\\nJavaScript on AWS\\n\\n\\n\\n Help\\n\\nContact Us\\nGet Expert Help\\nFile a Support Ticket\\nAWS re:Post\\nKnowledge Center\\nAWS Support Overview\\nLegal\\nAWS Careers\\n\\n\\n\\n\\n\\n\\n\\n  Create an AWS Account \\n\\n\\n\\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n \\n\\n\\n\\n\\n\\n          Amazon is an Equal Opportunity Employer: \\n          Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLanguage\\nعربي\\nBahasa Indonesia\\nDeutsch\\nEnglish\\nEspañol\\nFrançais\\nItaliano\\nPortuguês\\nTiếng Việt\\nTürkçe\\nΡусский\\nไทย\\n日本語\\n한국어\\n中文 (简体)\\n中文 (繁體)\\n\\n\\n\\n\\n\\n\\n\\n\\nPrivacy\\n|\\nAccessibility\\n|\\nSite Terms\\n|\\n Cookie Preferences \\n|\\n© 2024, Amazon Web Services, Inc. or its affiliates. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"]\n",
      "Extracting insights from: Just a moment...Enable JavaScript and cookies to continue\n",
      "Response: dict_keys(['candidates', 'create_time', 'response_id', 'model_version', 'prompt_feedback', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])\n",
      "Model: gemini-2.0-flash\n",
      "Usage: cached_content_token_count=None candidates_token_count=2582 prompt_token_count=24 total_token_count=2606\n",
      "Extracting insights from: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "What are Agentic Workflows? | IBM\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                        \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    What are agentic workflows?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                    Artificial Intelligence\n",
      "                                \n",
      "\n",
      "\n",
      "\n",
      "                                    IT automation\n",
      "                                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    7 March 2025\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                Link copied\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    Authors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Cole Stryker\n",
      "\n",
      "Editorial Lead, AI Models, Gather\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Anna Gutowska\n",
      "\n",
      "AI Engineer, Developer Advocate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "        What are agentic workflows?\r\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Agentic workflows are AI-driven processes where autonomous AI agents make decisions, take actions and coordinate tasks with minimal human intervention. These workflows leverage core components of intelligent agents such as reasoning, planning and tool use to execute complex tasks efficiently. Traditional automation such as robotic process automation (RPA), follow predefined rules and design patterns. This approach can be sufficient for repetitive tasks that follow a standard structure. Agentic workflows are dynamic, offering more flexibility by adapting to real-time data and unexpected conditions. AI Agentic workflows approach complex problems in a multistep, iterative way, enabling AI agents to break down business processes, adapt dynamically and refine their actions over time.\n",
      "By enabling generative AI to handle intricate workflows, organizations benefit from improved operational efficiency, scalability and informed decision-making. As we continue to see advancements in machine learning and natural language processing (NLP), AI technology is becoming more common in industries seeking to automate and optimize processes while reducing reliance on human oversight. The impacts of evolving AI models not only affect software development but also industries such as healthcare, finance, human resources and much more.  \n",
      "\n",
      "\n",
      "\r\n",
      "        How do agentic workflows work?\r\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Imagine a company has an IT support chatbot that follows a rule-based automation system. When an employee reports an issue (for example, \"My wifi isn’t working\"), the chatbot runs through static decision trees and provides predefined responses. If the problem isn’t resolved, the chatbot simply escalates to human support. This approach is efficient for basic, well-defined issues but struggles with complex, multistep troubleshooting that requires adaptability.\n",
      "With an agentic workflow, the IT assistant approaches troubleshooting as a multistep, iterative process. If an employee reports a wifi issue, the agent follows a dynamic step-by-step process for breaking down the workflow:\n",
      "Understanding the problem: The AI agent gathers detailed information from the employee, asking clarifying questions like, \"Are other devices connected to the network?\" or \"Did this start after a recent update?\"Executing diagnostic steps: Based on the user’s responses, the AI selects and runs different problem-solving steps. It might ping the router, check network logs or suggest specific settings changes, retrieving and summarizing this information for the user.\n",
      "Adaptive tool use: If the AI detects a server-side issue, it can call an internal monitoring tool API to check for outages. If the issue is device-specific, it can retrieve driver update suggestions or run a script to reset network settings.\n",
      "Iterating based on results: If an action doesn’t resolve the problem, the AI adjusts its approach dynamically. It might cross-check related issues, reattempt diagnostics or suggest a different solution instead of just escalating immediately.\n",
      "Finalizing and learning: If the issue is fixed, the AI logs the solution for future cases, improving its troubleshooting efficiency over time. If unresolved, it escalates with a detailed report, saving IT staff time by summarizing attempted fixes.\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "        Components of agentic workflows\r\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "The core components of agentic workflows consist of: \n",
      "AI agents - In artificial intelligence (AI), a workflow is not agentic if it does not consist of an AI agent. An AI agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.Large language models (LLMs) - At the core of AI agents are large language models. LLMs are crucial for processing and generating natural language. The adjustment of LLM parameters like temperature will also result in varying output quality.\n",
      "\n",
      "Tools - For an LLM to acquire information beyond the data used in training the model, we must provide tools. Examples of commonly used tools include external datasets, web searches and application programming interfaces (APIs). We can use tools to tailor an AI agent to specific use cases beyond routine tasks.\n",
      "\n",
      "Feedback mechanisms - Feedback mechanisms such as a human-in-the-loop (HITL) or even other agents can be valuable in facilitating the AI agent’s decision-making process and steering the agent output. \n",
      "\n",
      "Prompt engineering - Agentic workflow performance is heavily dependent on the quality of provided prompts. Prompt engineering helps generative AI models better comprehend and respond to a wide range of queries, from the simple to the highly technical. Common prompt engineering techniques include chain of thought (CoT), one-shot, zero-shot and self-reflection.\n",
      "\n",
      "Multiagent collaboration - Communication and distributed problem-solving within multiagent systems (MASs) are key for complex use cases. Each agent within a MAS can be designated a set of tools, algorithms and a domain of “expertise” so that agents are not all relearning the same information. Instead, agents are sharing their learned information with the rest of the MAS.  \n",
      "\n",
      "Integrations - To streamline existing processes, agentic workflows need to be integrated with the existing infrastructure. This synergy is dependent on the requirements and goals of the agentic workflow. Data integration, the process of consolidating data into a central database for the agent to access, is often the first step. Other forms of integrations include agent frameworks such as LangChain, LangGraph, crewAI and IBM’s BeeAI. These agent orchestration frameworks can serve as providers for achieving greater scale and performance. The integration of context-specific tools is also key to achieving relevant outputs.  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\r\n",
      "        The impact of agentic workflows\r\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "A personal anecdote from Andrew Ng, a leader in AI, highlights the adaptability of agentic workflows. Andrew recalls his demonstration of building AI agents, in which one of the many AI tools, a web search API, failed. The AI system was able to quickly handle the dependency failure by using an available Wikipedia search tool instead. The system completed the task and remained adaptable to the changing environment. The lessening need for human oversight might allow for our effort to be spent less on mundane, repetitive tasks and more on intricate work requiring human intelligence.  \n",
      "Andrew also explains that agentic workflows are meaningful not only for task execution but also for training the next generation of LLMs. In traditional, nonagentic workflows, using the output of one LLM to train another has not been found to lead to effective results. However, using an agentic workflow that produces high-quality data leads to useful training.  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Report\n",
      "        \n",
      "\n",
      "            Top Strategic Technology Trends for 2025: Agentic AI\n",
      "        \n",
      "Download this Gartner research to learn the potential opportunities and risks of agentic AI for IT leaders and learn how to prepare for this next wave of AI innovation.\r\n",
      "\r\n",
      "\n",
      "\n",
      "Read the report\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    Resources\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            News\n",
      "        \n",
      "\n",
      "            IBM’s answer to governing AI Agents: Automation and Evaluation with watsonx.governance\n",
      "        \n",
      "IBM announces how watsonx.governance enhances AI oversight, providing safer and more transparent AI deployment.\n",
      "\n",
      "Read the news\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Video\n",
      "        \n",
      "\n",
      "            Reimagine business productivity with AI agents and assistants\n",
      "        \n",
      "Learn how AI agents and AI assistants can work together to achieve new levels of productivity.\n",
      "\n",
      "Watch now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Podcast\n",
      "        \n",
      "\n",
      "            The future of agents, AI energy consumption, Anthropic's computer use and Google watermarking AI-generated text\n",
      "        \n",
      "Stay ahead of the curve with our AI experts on this episode of Mixture of Experts as they dive deep into the future of AI agents and more.\r\n",
      "\n",
      "\n",
      "Listen now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Demo\n",
      "        \n",
      "\n",
      "            Try watsonx Orchestrate\n",
      "        \n",
      "Explore how generative AI assistants can lighten your workload and improve productivity.\n",
      "\n",
      "Start the demo\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Podcast\n",
      "        \n",
      "\n",
      "            How AI agents will reinvent productivity\n",
      "        \n",
      "Learn ways to use AI to be more creative, efficient and start adapting to a future that involves working closely with AI agents.\n",
      "\n",
      "Listen now\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Report\n",
      "        \n",
      "\n",
      "            Omdia Report Empowered Intelligence: The Impact of AI Agents\n",
      "        \n",
      "Discover how you can unlock the full potential of Gen AI with AI agents.\r\n",
      "\n",
      "\n",
      "Read the report\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Report\n",
      "        \n",
      "\n",
      "            Is your organization ready to leverage genAI?\n",
      "        \n",
      "Explore this IDC Spotlight report to discover how you can unlock the full potential of your business data with GenAI.\r\n",
      "\r\n",
      "\n",
      "\n",
      "Read the report\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            Case study\n",
      "        \n",
      "\n",
      "            How Comparus is using a \"banking assistant\"\n",
      "        \n",
      "Comparus used solutions from IBM watsonx™ AI and impressively demonstrated the potential of Conversational banking as a new interaction model.\n",
      "\n",
      "Read the case study\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "            \n",
      "\n",
      "     \n",
      "    Related solutions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    IBM watsonx Orchestrate \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Streamline your workflows and reclaim your day with watsonx Orchestrate’s automation technology.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore watsonx Orchestrate\n",
      "            \n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    IBM AI agent solutions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "Build the future of your business with AI solutions that you can trust.\n",
      "\n",
      "\n",
      "\n",
      "Explore AI agent solutions\n",
      "            \n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "  \n",
      "    IBM AI consulting services\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "\n",
      "\n",
      "IBM Consulting AI services help reimagine how businesses work with AI for transformation.\n",
      "\n",
      "\n",
      "\n",
      "Explore artificial intelligence services\n",
      "            \n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Take the next step\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Whether you choose to customize pre-built apps and skills or build and deploy custom agentic services using an AI studio, the IBM watsonx platform has you covered.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Explore watsonx Orchestrate\n",
      "\n",
      "\n",
      "\n",
      "Explore watsonx.ai\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Response: dict_keys(['candidates', 'create_time', 'response_id', 'model_version', 'prompt_feedback', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])\n",
      "Model: gemini-2.0-flash\n",
      "Usage: cached_content_token_count=None candidates_token_count=644 prompt_token_count=2057 total_token_count=2701\n",
      "Extracting insights from: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building an AI simulation assistant with agentic workflows | AWS HPC Blog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Skip to Main Content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Click here to return to Amazon Web Services homepage\n",
      "\n",
      "\n",
      "\n",
      "About AWS\n",
      "Contact Us\n",
      " Support   \n",
      "       \n",
      "\n",
      " \n",
      " English   \n",
      "       \n",
      "\n",
      " \n",
      " My Account   \n",
      "       \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Sign In\n",
      "\n",
      "\n",
      "  Create an AWS Account \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Amazon Q\n",
      "Products\n",
      "Solutions\n",
      "Pricing\n",
      "Documentation\n",
      "Learn\n",
      "Partner Network\n",
      "AWS Marketplace\n",
      "Customer Enablement\n",
      "Events\n",
      "Explore More \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Close \n",
      "\n",
      "\n",
      "\n",
      "عربي\n",
      "Bahasa Indonesia\n",
      "Deutsch\n",
      "English\n",
      "Español\n",
      "Français\n",
      "Italiano\n",
      "Português\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tiếng Việt\n",
      "Türkçe\n",
      "Ρусский\n",
      "ไทย\n",
      "日本語\n",
      "한국어\n",
      "中文 (简体)\n",
      "中文 (繁體)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Close \n",
      "\n",
      "My Profile\n",
      "Sign out of AWS Builder ID\n",
      "AWS Management Console\n",
      "Account Settings\n",
      "Billing & Cost Management\n",
      "Security Credentials\n",
      "AWS Personal Health Dashboard\n",
      "\n",
      "\n",
      "\n",
      " Close \n",
      "\n",
      "Support Center\n",
      "Expert Help\n",
      "Knowledge Center\n",
      "AWS Support Overview\n",
      "AWS re:Post\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Click here to return to Amazon Web Services homepage\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Get Started for Free \n",
      "\n",
      "\n",
      "  Contact Us \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Products \n",
      " Solutions \n",
      " Pricing \n",
      " Introduction to AWS \n",
      " Getting Started \n",
      " Documentation \n",
      " Training and Certification \n",
      " Developer Center \n",
      " Customer Success \n",
      " Partner Network \n",
      " AWS Marketplace \n",
      " Support \n",
      " AWS re:Post \n",
      " Log into Console \n",
      " Download the Mobile App \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " AWS Blog Home\n",
      " Blogs  \n",
      " Editions  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Close \n",
      "\n",
      "\n",
      "\n",
      " Architecture\n",
      " AWS Cloud Operations\n",
      " AWS for Games\n",
      " AWS Insights\n",
      " AWS Marketplace\n",
      " AWS News\n",
      " AWS Partner Network\n",
      " AWS Smart Business\n",
      " Big Data\n",
      " Business Intelligence\n",
      " Business Productivity\n",
      " Cloud Enterprise Strategy\n",
      " Cloud Financial Management\n",
      " Compute\n",
      " Contact Center\n",
      " Containers\n",
      " Database\n",
      " Desktop & Application Streaming\n",
      " Developer Tools\n",
      " DevOps & Developer Productivity\n",
      " Front-End Web & Mobile\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " HPC\n",
      " IBM and Red Hat\n",
      " Industries\n",
      " Integration & Automation\n",
      " Internet of Things\n",
      " Machine Learning\n",
      " Media\n",
      " Messaging & Targeting\n",
      " Microsoft Workloads on AWS\n",
      " Migration and Modernization\n",
      " .NET on AWS\n",
      " Networking & Content Delivery\n",
      " Open Source\n",
      " Public Sector\n",
      " Quantum Computing\n",
      " Robotics\n",
      " SAP\n",
      " Security\n",
      " Spatial Computing\n",
      " Startups\n",
      " Storage\n",
      " Supply Chain & Logistics\n",
      " Training & Certification\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Close \n",
      "\n",
      "中国版\n",
      "日本版\n",
      "한국 에디션\n",
      "기술 블로그\n",
      "Edisi Bahasa Indonesia\n",
      "AWS Thai Blog\n",
      "Édition Française\n",
      "Deutsche Edition\n",
      "Edição em Português\n",
      "Edición en Español\n",
      "Версия на русском\n",
      "Türkçe Sürüm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AWS HPC Blog\n",
      "\n",
      "\n",
      "\n",
      "Building an AI simulation assistant with agentic workflows\n",
      "\n",
      "by Sam Bydlon\n",
      "on 28 MAY 2024\n",
      "in AWS Batch, Compute, High Performance Computing\n",
      "Permalink\n",
      " Share\n",
      "\n",
      "\n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Simulations have become indispensable tools which enable organizations to predict outcomes, evaluate risks, and make informed decisions. Simulations provide valuable insights that drive strategic decision-making – running the gamut from supply chain optimization to exploration of design alternatives for products and processes.\n",
      "But running and analyzing simulations can be a time-consuming task because it requires specialized teams of data scientists, analysts, and subject matter experts. In the manufacturing sector, these experts are in high demand to model and optimize complex production processes. This regularly leads to backlogs and delays in obtaining critical insights. In the healthcare industry, specialized teams of epidemiologists and statisticians run the simulations for infectious disease modeling that public health officials need to make decisions. The limited bandwidth of these specialists creates bottlenecks and inefficiencies that impact the ability to rapidly respond to emerging health crises in a data-driven manner.\n",
      "In this post, we’ll examine an generative AI-based “Simulation Assistant” demo application built using LangChain Agents and Anthropic’s recently released Claude V3 large language model (LLM) on Amazon Bedrock.\n",
      "By leveraging the latest advancements in LLMs and AWS, we’ll show you how to streamline and democratize your simulation workflows using a scalable and serverless architecture for an application with a chatbot-style interface. This will allow users to launch and interact with simulations using natural language prompts.\n",
      "How does this help experts?\n",
      "The Simulation Assistant demo offers a blueprint for providing significant value to organizations in two key ways. It:\n",
      "\n",
      "Democratizes simulation-driven problem solving: While regulated industries may still require certified personnel for final sign-off, this solution demonstrates a way to democratize simulation use beyond specialist teams. By enabling knowledgeable personnel across functions, such as analysts, managers, and decision-makers, to launch and analyze simulations under the guidance of experts, organizations can increase the utilization of simulation capabilities and free up the bandwidth of their simulation experts.\n",
      "Enhances efficiency for simulation experts: Allowing a wider user-base to run routine simulations lets experts focus on high value tasks like performance tuning or building new simulations. Streamlined, automated workflows accessible through a single chatbot interface improves productivity, standardizes processes, enables knowledge sharing, and increases result reliability.\n",
      "\n",
      "Whether you’re a business analyst, product manager, researcher, or a simulation expert, this demonstration offers an intuitive and efficient way to harness the power of simulations by leveraging the capabilities of generative AI through Amazon Bedrock and the scalability of AWS – driving innovation and operational excellence across diverse industries.\n",
      "Solution overview\n",
      "\n",
      "\n",
      "Figure 1 – Architectural diagram for Simulation Assistant application. A containerized Streamlit web app is deployed via a load-balanced AWS Fargate service. The web app instantiates an LLM-based agent with access to seven tools. The retriever tool provides RAG capabilities using Amazon Kendra. Others tools enable the agent to perform a custom mathematical transform, invoke a simple inflation simulation executed using AWS Lambda, invoke a set of containerized investment portfolio simulations using AWS Batch that store results in an Amazon DynamoDB table, and analyze a batch of simulation results by generating plots.\n",
      "\n",
      "Figure 1 depicts the architecture of the Simulation Assistant application. A web application, built using Streamlit, serves as the user interface. Streamlit is an open-source Python library that allows you to create interactive web applications for machine learning and data science use cases. We’ve containerized this app using Docker and stored it in an Amazon Elastic Container Registry (ECR) repository.\n",
      "The containerized web application is deployed as a load-balanced AWS Fargate Service within an Amazon Elastic Container Service (ECS) cluster. AWS Fargate is a serverless compute engine that allows you to run containers without managing servers or clusters. By using Fargate, the Simulation Assistant application can scale its compute resources up or down automatically based on the incoming traffic, ensuring optimal performance and cost-efficiency.\n",
      "The web application is fronted by an Application Load Balancer (ALB). The ALB distributes incoming traffic across multiple targets, like Fargate tasks, in a balanced manner. This load balancing mechanism ensures that user requests are efficiently handled, even during periods of high traffic, by dynamically routing requests to available container instances.\n",
      "Life cycle of a request\n",
      "When a user accesses the Simulation Assistant application, their request is received by the ALB, which then forwards the request to one of the healthy Fargate tasks running the Streamlit web application. This serverless deployment approach, combined with the load-balancing capabilities of the ALB, provides a highly available and scalable architecture for the Simulation Assistant, allowing it to handle varying levels of user traffic without the need for manually provisioning and managing servers.\n",
      "The Streamlit web application acts as the central hub, orchestrating the interaction between different AWS services to enable seamless simulation capabilities for users. Within the Streamlit app, we’ve used Amazon Bedrock to process user queries by leveraging state-of-the-art language models. Bedrock is a fully-managed service that makes these art foundation models from both Amazon and leading AI startups available via a unified API, while abstracting away complex model management.\n",
      "For simple simulations, like price inflation scenarios, the Streamlit app integrates with AWS Lambda functions. These serverless functions can encapsulate lightweight simulation logic, allowing for efficient execution and scalability without the need for provisioning and managing dedicated servers.\n",
      "Additionally, we’re also leveraging Amazon Kendra, an intelligent search service, to enable retrieval augmented generation (RAG). Amazon Kendra indexes and searches through documents stored in an Amazon S3 bucket, acting as a source repository. This integration empowers the application to provide relevant information from existing documents, enhancing the simulation capabilities and enabling more informed decision-making.\n",
      "For more computationally intensive simulations, like running sets of investment portfolio simulations in a Monte Carlo-style manner, the Simulation Assistant uses AWS Batch. AWS Batch is a fully managed batch processing service that efficiently runs batch computing workloads across AWS resources. The Simulation Assistant submits jobs to AWS Batch, which then dynamically provisions the compute resources needed to run them in parallel, enabling faster execution times and scalability.\n",
      "Once the simulations are complete, the results are stored in an Amazon DynamoDB database, a fully managed NoSQL database service. DynamoDB provides fast and predictable performance with seamless scalability, making it well-suited for storing and retrieving simulation data efficiently. Furthermore, the application integrates with Amazon EventBridge, a serverless event bus service. When a simulation batch is finished, EventBridge triggers a notification, which is sent to the user via email using Amazon Simple Notification Service (SNS). This notification system keeps users informed about the completion of their simulation requests, allowing them to promptly access and analyze the results.\n",
      "LLM-based “agents” with “tools”\n",
      "The Streamlit web application houses the logic of the key technological concept underlying the Simulation Assistant application, the enablement of what is called “agentic behavior” of an LLM. The precise definition of an LLM agent is elusive, because the field is relatively new and rapidly evolving. But the general idea is to augment the capabilities of LLMs by enabling the models to break down tasks into individual steps, make plans, and take actions including the use of tools to solve specific tasks, and even work together as a team of multiple agents that can collaborate and influence each other.\n",
      "One design pattern for enabling agentic behavior of is called “Tool Use”, in which an LLM is taught (through prompt engineering or fine-tuning) how to trigger pieces of additional software, wrapped in a standardized form like a function call. These additional pieces of software are called “tools”. The Simulation Assistant employs tools to augment the behavior of an underlying foundation model. In our demo, the underlying foundation model is Claude V3 Sonnet.\n",
      "Tools help LLMs solve problems that are not reliably solved by direct generation using the underlying transformer network. LLMs are demonstrating incredible ability at solving problems and performing mathematical reasoning – try asking Claude V3 Sonnet to “simulate the price of milk over the next 20 years with a dynamic inflation rate where the mean is 4% and standard deviation 2%”. But their ability to simulate more complex systems like financial markets or the spread of wildfires is still (for now) best left to trusted simulation codes. By introducing tools that can execute those trusted codes and instructing the LLM on how and when tools should be used, LLMs can gain profound new abilities.\n",
      "There are many possibilities for what tools can be and do, and the application of tools and agentic behavior in general is a concept that will have wide ranging uses cases far beyond simulation. Tools can help LLMs to perform web searches, query a database, or schedule a meeting using your calendar system, just to name a few options.\n",
      "How we applied agents and tools\n",
      "The Simulation Assistant instantiates a LangChain agent, based on Claude V3 Sonnet. LangChain is an open-source framework for building applications with LLMs. With LangChain Agents and Tools, developers can create powerful generative AI-based applications that leverage LLM agentic behavior and integrate with existing systems and workflows.\n",
      "There are several kinds of agents that can be constructed with LangChain, but not all agent types support tools with multiple inputs. Since simulations often require users to specify an array of input parameters to define the system mechanics to be simulated, we’ll want to choose an agent type that supports multi-input tools and can be used in concert with Amazon Bedrock. The Simulation Assistant demo uses a structured chat agent, which satisfies both of these requirements.\n",
      "Building the Simulation Assistant involved addressing several key technical challenges:\n",
      "\n",
      "Designing and implementing an agent-tool architecture: To create an effective agent-tool system, careful design of the tool interfaces and integration with the LangChain agent framework was required. We handled multi-input tools by defining structured input schemas. We enabled communication between the LLM and the tools using LangChain’s tool abstraction layer.\n",
      "Prompt engineering for agentic behavior: Crafting prompts that guide the LLM to exhibit desired agentic behavior was an iterative process. The approach involved exploring the capabilities and limitations of Claude V3 Sonnet, designing prompts that promoted appropriate tool selection and usage, and refining the prompts based on performance in test scenarios.\n",
      "Scaling and managing simulation workloads: To handle computationally intensive simulations, we designed a scalable architecture using AWS Batch for running simulation jobs. This allowed us to efficiently manage compute resources and reliably execute simulations with varying workloads.\n",
      "Interpreting and visualizing simulation results: To help users interpret and visualize simulation outputs, we developed tools that process and summarize simulation data, and integrated visualizations within Simulation Assistant.\n",
      "\n",
      "We gave the Simulation Assistant agent access to seven tools, including ones designed to perform a custom mathematical transform defined within the Streamlit application, perform simple inflation simulations housed in an AWS Lambda function, launch Monte Carlo-style simulation ensembles via AWS Batch to mimic an investment portfolio and visualize results, and to perform RAG over an internal database of documents.\n",
      "These are simple examples, showing how tools can be built to handle some common elements of simulation workflows. But tools can do a lot more: they can also be designed to prepare configuration files, trigger pre- or post-processing jobs on related data – or even call other specialized LLMs that are able to interpret and summarize the results of simulations.\n",
      "A sample workflow\n",
      "When a user enters a natural language query into Simulation Assistant like, “run a set of 100 investment simulations starting at $10,000, with cash flow of $250, for 50 steps,” we pass the query to Amazon Bedrock inside a prompt specifically engineered to work well in an agent-tool setting. You can find examples of polished prompts you can use at the LangChain Hub – including prompts that work well with structured chat agents.\n",
      "Behind the scenes, the agentic LLM breaks down the request into steps, decides whether each step can be completed with “bare hands” (i.e. without tools), or whether one of its tools can be used to complete the step. For our example request, the agentic LLM determines that it needs to use a tool that allows it to run batches of investment portfolio simulations, performs the entity extraction of the key parameters like cash flow, and uses these parameters to trigger an AWS Batch job to run the simulations. It does this completely independently.\n",
      "The agent then responds to the user telling them they’ll receive an email when the simulations are complete and provides some helpful information that can be used to analyze the simulation results.\n",
      "Figure 2 is a graphical depiction of this process.\n",
      "\n",
      "\n",
      "Figure 2 – Workflow of an LLM-based agent with tools for batch simulation execution. User requests are formatted into prompts by the application and sent to the LLM, which decomposes the request, selects and triggers the appropriate tool with extracted parameters (run_batch_simulations tool with simulation inputs). Tool results are returned to the LLM for generating a final response displayed to the user, including information for accessing and analyzing simulation outputs.\n",
      "\n",
      "For a deeper look into how we used these tools and to see the Simulation Assistant demo in action (including the batch simulation query described above) you can check out the video demo below. This will walk you through some potential interactions with the application, and shows the LLM-based agent interacting with various tools representing different aspects of a simulation workflow. You’ll see the agent list the available tools and provide instructions on how to use them when prompted.\n",
      "\n",
      "Figure 3 – A video showing the Simulation Assistant demo in action. Click to play.\n",
      "The core portion of the demo involves the user asking the agent to run a set of 100 investment portfolio simulations with specific parameters like starting amount, cash flow, and number of steps. The agent interprets this natural language query, extracts the necessary parameters, and triggers an AWS Batch job to execute the simulations in parallel. Once the simulations complete, the agent retrieves the results from a database and visualizes them using another tool.\n",
      "Additionally, the video contrasts the agent’s capabilities with a standard LLM’s response to the same query, so you can see the enhanced abilities provided by the agent-tool architecture. You’ll also notice the agent breaking down a complex problem into steps and leveraging multiple tools in different orders to solve it, demonstrating the flexibility of the approach.\n",
      "Future Work\n",
      "While the Simulation Assistant demo achieves a lot, we want to extend the demo in the future to tackle some more technical challenges:\n",
      "\n",
      "Integrating with existing simulation codebases: A key goal of ours is to integrate existing simulation codebases as tools within the agent-tool architecture. This will require a deep understanding of the codebases and, in some cases, modifying them to fit the tool interface requirements. For example, to integrate OpenFOAM (a popular open-source computational fluid dynamics software) as a tool, the approach would involve wrapping OpenFOAM’s solver and utility executables as Python functions, defining input and output schemas, and potentially modifying the codebase to enable programmatic execution and data exchange.\n",
      "Ensuring simulation reproducibility and traceability: We’d like to enable comprehensive reproducibility and traceability of the simulation runs by implementing logging mechanisms that track input parameters, intermediate steps, and provide detailed documentation for each simulation execution.\n",
      "Establishing guardrails: Guardrails and safeguards are crucial to ensure the secure and responsible use of the simulation framework. This may involve setting limits on compute resources, enforcing access controls, and implementing validation checks to prevent potential misuse or unintended consequences. Additionally, ethical considerations should be considered, like ensuring privacy and data protection, avoiding biases, and promoting transparency in the simulation processes.\n",
      "\n",
      "Conclusion\n",
      "This post introduces an AWS-native Simulation Assistant demo that we hope will provide inspiration, and a blueprint, for organizations looking to leverage generative AI and other cutting-edge techniques like agentic LLM behavior to help their businesses.\n",
      "The demo shows the potential of these technologies for revolutionizing simulation workflows across various industries. Using LangChain Agents, Amazon Bedrock, and the scalability of AWS services, the Simulation Assistant demo can offer a glimpse into a future where simulations might be more accessible and interactive. We hope this will let organizations unlock new insights and drive better decision-making.\n",
      "The application of agentic LLM frameworks extend far beyond simulations, and the concept of tools can be applied to a countless number of domains or workflows. By enabling LLMs to interact with external systems, perform computations, and trigger actions, organizations can augment their existing processes in this way, fostering innovation and operational excellence.\n",
      "Solutions like this can also pave the way for new paradigms in human-machine collaboration, amplifying human capabilities and accelerating the pace of discovery.\n",
      "If your organization is interested in exploring how to implement these techniques in concert with your workflows, we encourage you to reach out to your AWS account team, or send an email to ask-hpc@amazon.com.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         TAGS: \n",
      "        AWS Batch, HPC, Machine Learning, ML, simulations\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sam Bydlon\n",
      "Dr. Sam Bydlon is a Specialist Solutions Architect with the Advanced Compute, Emerging Technologies team at AWS. Sam received his Ph.D. in Geophysics from Stanford University in 2018 and has 12 years of experience developing and utilizing simulations in research science and financial services. In his spare time, Sam enjoys camping, waterfalls, and camping near waterfalls.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Resources\n",
      "\n",
      "\n",
      "HPC on AWS Overview\n",
      "HPC Tech Shorts Video Series\n",
      "HPC Community Site\n",
      "AWS Quantum Technologies Blog\n",
      "AWS ParallelCluster\n",
      "AWS Batch\n",
      "NICE DCV\n",
      "Elastic Fabric Adapter\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Follow\n",
      "\n",
      "\n",
      " Twitter\n",
      " Facebook\n",
      " LinkedIn\n",
      " Twitch\n",
      " Email Updates\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Sign In to the Console \n",
      "\n",
      " Learn About AWS\n",
      "\n",
      "What Is AWS?\n",
      "What Is Cloud Computing?\n",
      "AWS Accessibility\n",
      "AWS Inclusion, Diversity & Equity\n",
      "What Is DevOps?\n",
      "What Is a Container?\n",
      "What Is a Data Lake?\n",
      "What is Artificial Intelligence (AI)?\n",
      "What is Generative AI?\n",
      "What is Machine Learning (ML)?\n",
      "AWS Cloud Security\n",
      "What's New\n",
      "Blogs\n",
      "Press Releases\n",
      "\n",
      "\n",
      "\n",
      " Resources for AWS\n",
      "\n",
      "Getting Started\n",
      "Training and Certification\n",
      "AWS Solutions Library\n",
      "Architecture Center\n",
      "Product and Technical FAQs\n",
      "Analyst Reports\n",
      "AWS Partners\n",
      "\n",
      "\n",
      "\n",
      " Developers on AWS\n",
      "\n",
      "Developer Center\n",
      "SDKs & Tools\n",
      ".NET on AWS\n",
      "Python on AWS\n",
      "Java on AWS\n",
      "PHP on AWS\n",
      "JavaScript on AWS\n",
      "\n",
      "\n",
      "\n",
      " Help\n",
      "\n",
      "Contact Us\n",
      "Get Expert Help\n",
      "File a Support Ticket\n",
      "AWS re:Post\n",
      "Knowledge Center\n",
      "AWS Support Overview\n",
      "Legal\n",
      "AWS Careers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  Create an AWS Account \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          Amazon is an Equal Opportunity Employer: \n",
      "          Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Language\n",
      "عربي\n",
      "Bahasa Indonesia\n",
      "Deutsch\n",
      "English\n",
      "Español\n",
      "Français\n",
      "Italiano\n",
      "Português\n",
      "Tiếng Việt\n",
      "Türkçe\n",
      "Ρусский\n",
      "ไทย\n",
      "日本語\n",
      "한국어\n",
      "中文 (简体)\n",
      "中文 (繁體)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Privacy\n",
      "|\n",
      "Accessibility\n",
      "|\n",
      "Site Terms\n",
      "|\n",
      " Cookie Preferences \n",
      "|\n",
      "© 2024, Amazon Web Services, Inc. or its affiliates. All rights reserved.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Response: dict_keys(['candidates', 'create_time', 'response_id', 'model_version', 'prompt_feedback', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])\n",
      "Model: gemini-2.0-flash\n",
      "Usage: cached_content_token_count=None candidates_token_count=1101 prompt_token_count=4484 total_token_count=5585\n",
      "Insights: ['Okay, let\\'s dive into research on agents and agentic workflows.  This is a rapidly evolving field within AI, so it\\'s important to consider both the foundational concepts and the current cutting edge.\\n\\n**I. Defining Agents and Agentic Workflows**\\n\\n*   **Agent:**  An agent is an entity (software or hardware) that can perceive its environment through sensors, reason about its environment using internal knowledge and goals, and act upon that environment through actuators or outputs to achieve its goals. Key characteristics include:\\n    *   *Autonomy:* Operates without direct human intervention.\\n    *   *Reactivity:* Responds to changes in its environment.\\n    *   *Proactiveness:*  Takes initiative to achieve its goals.\\n    *   *Social Ability:* (Often, but not always) Interacts with other agents or humans.\\n*   **Agentic Workflow:** A structured process or series of tasks orchestrated by one or more agents working together (or independently) to accomplish a complex goal. This involves:\\n    *   *Task Decomposition:* Breaking down a large goal into smaller, manageable sub-tasks.\\n    *   *Planning and Execution:* Agents generating plans to achieve sub-tasks and executing those plans.\\n    *   *Communication and Coordination:* Agents communicating with each other to share information, negotiate, and coordinate their actions.\\n    *   *Monitoring and Adaptation:* Agents monitoring their progress, detecting failures, and adapting their plans as needed.\\n\\n**II. Key Research Areas and Challenges:**\\n\\nHere\\'s a breakdown of crucial research areas and the challenges within each:\\n\\n*   **Agent Architectures:**\\n    *   *Research:*  Focuses on the internal structure and organization of agents.  Common architectures include:\\n        *   *Symbolic (Deliberative) Agents:*  Rely on explicit knowledge representation (e.g., rules, ontologies) and logical reasoning.\\n        *   *Reactive Agents:*  Based on simple stimulus-response rules, often using finite state machines or behavior-based systems.\\n        *   *Hybrid Agents:*  Combine symbolic and reactive elements to leverage the strengths of both.  (e.g., a hierarchical architecture where high-level planning is symbolic, and low-level execution is reactive).\\n        *   *Reinforcement Learning Agents:* Learn optimal actions through trial and error in an environment, maximizing a reward signal.\\n        *   *LLM-based Agents:* Utilizing Large Language Models as the core decision-making engine, leveraging their capabilities in natural language understanding, reasoning, and code generation.\\n    *   *Challenges:*\\n        *   *Scalability:*  Designing architectures that can handle increasingly complex environments and goals.\\n        *   *Explainability:*  Understanding why an agent makes a particular decision (especially crucial for symbolic and LLM-based agents).\\n        *   *Robustness:*  Ensuring that agents can operate reliably in uncertain or adversarial environments.\\n        *   *Adaptability:*  Creating agents that can learn and adapt to new situations and goals without requiring complete retraining.\\n        *   *Memory & Context Handling (for LLM agents):*  Overcoming the limitations of LLM context windows to enable long-term planning and reasoning.  Techniques like vector databases and memory retrieval are actively being researched.\\n\\n*   **Planning and Decision-Making:**\\n    *   *Research:*  Developing algorithms and techniques that allow agents to generate plans, make decisions, and solve problems.\\n        *   *Classical Planning:*  Uses symbolic representations and search algorithms (e.g., A*, STRIPS) to find optimal plans.\\n        *   *Heuristic Search:*  Employs heuristics to guide the search for solutions in complex problem spaces.\\n        *   *Decision Theory:*  Provides a framework for making decisions under uncertainty, using concepts like expected utility.\\n        *   *Multi-Agent Planning:*  Extends planning techniques to scenarios involving multiple agents, requiring coordination and negotiation.\\n    *   *Challenges:*\\n        *   *Handling Uncertainty:*  Developing plans that are robust to unexpected events.\\n        *   *Computational Complexity:*  Finding efficient planning algorithms that can scale to large and complex problems.\\n        *   *Real-Time Planning:*  Generating plans quickly enough to respond to rapidly changing environments.\\n        *   *Integrating Planning and Learning:*  Combining planning with reinforcement learning to enable agents to learn from experience and improve their planning abilities.\\n        *   *Commonsense Reasoning:* Equipping agents with the background knowledge and reasoning abilities needed to understand and interact with the world in a human-like way.\\n\\n*   **Communication and Coordination:**\\n    *   *Research:*  Investigating how agents can communicate with each other, share information, and coordinate their actions to achieve common goals.\\n        *   *Agent Communication Languages (ACLs):*  Formal languages for expressing agent intentions and exchanging information. (e.g., KQML, FIPA-ACL).\\n        *   *Coordination Mechanisms:*  Protocols and algorithms for agents to agree on plans, allocate resources, and resolve conflicts. (e.g., contract net protocol, auctions).\\n        *   *Game Theory:*  Provides a mathematical framework for analyzing strategic interactions between agents.\\n        *   *Emergent Coordination:*  Coordination that arises spontaneously from the interactions of agents, without explicit communication.\\n    *   *Challenges:*\\n        *   *Scalability:*  Designing communication protocols that can handle large numbers of agents.\\n        *   *Robustness:*  Ensuring that communication remains reliable even in the presence of noise, errors, or malicious agents.\\n        *   *Trust and Security:*  Establishing trust between agents and protecting against attacks.\\n        *   *Human-Agent Interaction:*  Developing natural and intuitive ways for humans to interact with and coordinate with agents.\\n        *   *Semantic Interoperability:*  Ensuring that agents can understand each other\\'s messages, even if they use different representations or ontologies.  (A major challenge for distributed, heterogeneous agent systems.)\\n\\n*   **Learning and Adaptation:**\\n    *   *Research:*  Developing techniques that allow agents to learn from experience, adapt to new environments, and improve their performance over time.\\n        *   *Reinforcement Learning (RL):*  Agents learn to maximize a reward signal through trial and error.\\n        *   *Imitation Learning:*  Agents learn by observing the actions of an expert.\\n        *   *Transfer Learning:*  Agents transfer knowledge learned in one environment to another.\\n        *   *Meta-Learning:*  Agents learn how to learn, allowing them to quickly adapt to new tasks.\\n    *   *Challenges:*\\n        *   *Sample Efficiency:*  Learning effectively from limited data.\\n        *   *Exploration vs. Exploitation:*  Balancing the need to explore new actions with the need to exploit known good actions.\\n        *   *Reward Shaping:*  Designing reward functions that effectively guide learning.\\n        *   *Generalization:*  Ensuring that learned policies generalize to unseen environments.\\n        *   *Catastrophic Forgetting:*  Preventing agents from forgetting previously learned knowledge when learning new tasks.\\n        *   *Safety:**  Ensuring that learning agents do not perform actions that could be harmful or dangerous.\\n\\n*   **Applications of Agentic Workflows:**\\n    *   *Research:*  Applying agent technology to solve real-world problems in areas such as:\\n        *   *Robotics:*  Autonomous robots for manufacturing, logistics, and exploration.\\n        *   *Smart Homes/Cities:*  Intelligent systems for managing energy, transportation, and security.\\n        *   *Healthcare:*  Diagnostic tools, personalized treatment plans, and robotic surgery.\\n        *   *Finance:*  Algorithmic trading, risk management, and fraud detection.\\n        *   *Supply Chain Management:*  Optimizing logistics, inventory control, and procurement.\\n        *   *Information Retrieval and Filtering:*  Personalized search engines, recommender systems, and spam filters.\\n        *   *Software Engineering:*  Automated testing, code generation, and debugging.\\n    *   *Challenges:*\\n        *   *Integration:*  Integrating agent systems with existing infrastructure and legacy systems.\\n        *   *Trust and Acceptance:*  Gaining user trust and acceptance of agent-based systems.\\n        *   *Ethical Considerations:*  Addressing the ethical implications of autonomous agents, such as bias, fairness, and accountability.\\n        *   *Security:*  Protecting agent systems from cyberattacks and ensuring data privacy.\\n        *   *Scalability:** Building agentic workflows that can handle large amounts of data and complex tasks.\\n\\n**III. Current Trends and Emerging Areas:**\\n\\n*   **LLM-Powered Agents:** This is arguably the hottest area right now.  Researchers are exploring how to leverage the power of Large Language Models (LLMs) for planning, reasoning, and decision-making within agent frameworks.  Key research topics include:\\n    *   *Prompt Engineering for Agents:*  Crafting effective prompts to guide LLMs in performing specific tasks.\\n    *   *Tool Use:*  Enabling LLMs to interact with external tools and APIs to augment their capabilities.  (e.g., using a search engine, a calculator, or a database).\\n    *   *Memory Management:*  Overcoming the limitations of LLM context windows by using techniques like vector databases and memory retrieval.\\n    *   *Agent Orchestration:*  Developing frameworks for coordinating multiple LLM-based agents to solve complex problems.\\n    *   *Fine-tuning LLMs for Agentic Tasks:* Training LLMs specifically for agentic tasks to improve their performance.\\n\\n*   **Human-in-the-Loop Agent Systems:**  Recognizing that fully autonomous agents are not always desirable or feasible, research is focusing on systems where humans and agents collaborate closely.\\n    *   *Explainable AI (XAI):*  Making agent decisions transparent and understandable to humans.\\n    *   *Interactive Planning:*  Allowing humans to guide and refine agent plans.\\n    *   *Trust Modeling:*  Developing models of human trust in agents to improve collaboration.\\n\\n*   **Agent Swarms and Collective Intelligence:**  Inspired by biological systems like ant colonies and bee swarms, researchers are exploring how large numbers of simple agents can collectively solve complex problems.\\n    *   *Decentralized Control:*  Designing systems where agents make decisions locally, without central coordination.\\n    *   *Stigmergy:*  Agents indirectly communicate by modifying their environment.\\n    *   *Self-Organization:*  Patterns and structures emerge spontaneously from the interactions of agents.\\n\\n*   **Formal Verification of Agent Systems:**  Developing formal methods to verify the correctness, safety, and security of agent systems.  This is particularly important for safety-critical applications.\\n\\n**IV.  Important Resources for Further Research:**\\n\\n*   **Conferences:**\\n    *   AAMAS (International Conference on Autonomous Agents and Multiagent Systems)\\n    *   AAAI (Association for the Advancement of Artificial Intelligence)\\n    *   IJCAI (International Joint Conference on Artificial Intelligence)\\n    *   ICRA (IEEE International Conference on Robotics and Automation)\\n    *   IROS (IEEE/RSJ International Conference on Intelligent Robots and Systems)\\n*   **Journals:**\\n    *   Autonomous Agents and Multi-Agent Systems (JAAMAS)\\n    *   Artificial Intelligence (AIJ)\\n    *   Journal of Artificial Intelligence Research (JAIR)\\n    *   IEEE Transactions on Robotics\\n*   **arXiv (Preprint Server):**  A great place to find the latest research papers.  Search for keywords like \"autonomous agents,\" \"multi-agent systems,\" \"agentic workflows,\" \"LLM agents,\" etc.\\n*   **GitHub:**  Many researchers and developers share their agent-related code and projects on GitHub.  Search for repositories related to agent frameworks, planning algorithms, and LLM-based agents.\\n\\n**In Conclusion:**\\n\\nThe field of agents and agentic workflows is dynamic and multifaceted.  By focusing on the core principles, understanding the current challenges, and staying abreast of emerging trends, you can effectively navigate this exciting area of AI research. Remember to focus on the intersection of theory and practice, and consider the ethical implications of deploying autonomous agents in real-world settings. Good luck with your research!\\n', 'Okay, I\\'ve reviewed the provided IBM article on \"Agentic Workflows.\" Here\\'s a summary of the key research points and a breakdown of the topic:\\n\\n**Core Concept:**\\n\\n*   **Agentic workflows are AI-driven processes where autonomous AI agents make decisions, take actions, and coordinate tasks with minimal human intervention.**  They go beyond traditional rule-based automation by adapting to real-time data and unexpected conditions.\\n\\n**How Agentic Workflows Work:**\\n\\n*   **Multistep, Iterative Approach:** AI agents break down complex problems into smaller steps, dynamically adapt their actions, and refine them over time.\\n*   **Example (IT Support):**  Instead of following a static decision tree, an AI IT assistant can:\\n    *   Understand the problem through detailed questioning.\\n    *   Execute diagnostic steps (pinging router, checking logs).\\n    *   Use tools adaptively (call monitoring tool APIs, retrieve driver updates).\\n    *   Iterate based on results (cross-check related issues, reattempt diagnostics).\\n    *   Finalize and learn from each interaction.\\n\\n**Key Components of Agentic Workflows:**\\n\\n1.  **AI Agents:**  The fundamental building block – a system capable of autonomously performing tasks and designing its workflow.\\n2.  **Large Language Models (LLMs):** Crucial for processing and generating natural language. LLM parameters like temperature need to be adjusted for varying output quality.\\n3.  **Tools:**  Enable LLMs to access information beyond their training data (e.g., external datasets, web searches, APIs).\\n4.  **Feedback Mechanisms:** Human-in-the-loop (HITL) or other agents can guide the AI agent\\'s decision-making.\\n5.  **Prompt Engineering:** High-quality prompts are essential for good performance (techniques include chain of thought, one-shot, zero-shot, and self-reflection).\\n6.  **Multiagent Collaboration:** Communication and distributed problem-solving within multiagent systems (MASs) are essential for complex use cases.\\n7.  **Integrations:** Integrating agentic workflows with existing infrastructure and data sources is crucial. This includes using agent frameworks (LangChain, LangGraph, crewAI, BeeAI) and context-specific tools.\\n\\n**Impact of Agentic Workflows:**\\n\\n*   **Improved Operational Efficiency and Scalability:**  Automating complex tasks and adapting to changing conditions.\\n*   **Informed Decision-Making:**  Providing AI-driven insights and recommendations.\\n*   **Reduced Reliance on Human Oversight:**  Freeing up human workers for more complex tasks.\\n*   **Training Next-Generation LLMs:** Agentic workflows can produce high-quality data for training more effective LLMs.\\n*   **Adaptability:** AI systems can quickly handle dependency failures by using other available tools to complete the task.\\n\\n**In essence, agentic workflows represent a shift from rigid automation to more flexible and intelligent AI-driven processes. They hold the potential to transform various industries by enabling AI to handle complex tasks with minimal human intervention.**\\n', 'Okay, I\\'ve reviewed the AWS HPC Blog post titled \"Building an AI simulation assistant with agentic workflows.\" Here\\'s a summary of the research landscape it addresses, key takeaways, and potential future research directions, framed from a researcher\\'s perspective:\\n\\n**Research Landscape Addressed**\\n\\n*   **Democratization of Simulation:** The post tackles the problem of limited access to simulation tools and expertise within organizations. Currently, simulation workflows often require specialized data scientists, analysts, and subject matter experts, creating bottlenecks and delays.\\n*   **Generative AI for Simulation Workflows:** The post explores how Large Language Models (LLMs) and agentic workflows can streamline and democratize simulation processes. It directly investigates the application of LLMs, specifically Anthropic\\'s Claude V3, to manage and interact with simulations through natural language prompts.\\n*   **Agentic AI and Tool Use:** The core of the research focuses on \"agentic behavior\" of LLMs, particularly the \"Tool Use\" design pattern. It examines how LLMs can be augmented with specialized software components (\"tools\") to perform complex tasks, specifically in the context of simulation.\\n*   **Scalable and Serverless Architectures for AI-Driven Simulation:** The post showcases a cloud-based architecture leveraging AWS services (Fargate, Lambda, Batch, Kendra, DynamoDB, EventBridge, SNS) to build a scalable and serverless \"Simulation Assistant.\"\\n\\n**Key Research Takeaways**\\n\\n*   **LLMs as Orchestrators of Simulations:** The primary finding is that LLMs can effectively orchestrate simulation workflows by understanding natural language requests, breaking them down into steps, and using tools to execute specific tasks, including launching simulations and analyzing results.\\n*   **Tool Use Enables Complex Problem Solving:** The \"Tool Use\" pattern is crucial. LLMs can leverage existing simulation codes and specialized functionalities by integrating them as tools, significantly expanding their problem-solving capabilities. The post demonstrates how even a relatively simple LLM like Claude V3 Sonnet can be very effective.\\n*   **Benefits for Experts and Non-Experts:** The approach can benefit both simulation experts (by automating routine tasks and freeing up their time for more complex tasks) and non-experts (by providing an accessible interface for running and analyzing simulations under expert guidance).\\n*   **Cloud-Based Architecture Enables Scalability and Efficiency:** Using AWS services provides a scalable and cost-effective way to deploy and manage the Simulation Assistant, handling varying workloads and ensuring high availability.\\n*   **Structured Chat Agents:** Structured chat agents support multi-input tools and can be used in concert with Amazon Bedrock.\\n\\n**Potential Future Research Directions**\\n\\n*   **Integration with Existing Simulation Codebases:** The post identifies this as a critical area for future work. Research is needed on how to seamlessly integrate diverse and complex simulation codes (e.g., OpenFOAM, proprietary software) as tools within agentic LLM workflows. This includes addressing issues of code modification, input/output standardization, and programmatic execution.\\n*   **Simulation Reproducibility and Traceability:** Ensuring the reproducibility and traceability of simulation results is paramount. Research should focus on developing robust logging mechanisms, data provenance tracking, and documentation standards for AI-driven simulation workflows.\\n*   **Guardrails and Ethical Considerations:** Research is needed to establish appropriate guardrails and safeguards for the responsible use of AI-driven simulation frameworks. This includes setting limits on compute resources, enforcing access controls, implementing validation checks, and addressing ethical considerations such as bias mitigation, data privacy, and transparency.\\n*   **Tool Design and Optimization:** The effectiveness of the agentic workflow heavily relies on the quality and design of the \"tools.\" Research should explore optimal tool design principles, including input/output schemas, error handling, and communication protocols between LLMs and tools.\\n*   **Multi-Agent Simulation Workflows:** Explore the potential of multiple agents that can collaborate and influence each other.\\n*   **LLM Fine-Tuning for Simulation Tasks:** Investigate the benefits of fine-tuning LLMs on simulation-specific tasks and datasets to improve their understanding of simulation parameters, results, and workflows.\\n*   **Explainable AI (XAI) for Simulation Results:** Develop techniques to make the decision-making process of the LLM agent transparent and understandable, particularly in the context of simulation result analysis. XAI methods can help users understand why the agent selected certain tools or drew specific conclusions from the simulation data.\\n*   **Real-World Validation and Case Studies:** Conduct real-world case studies in various industries (manufacturing, healthcare, finance, etc.) to validate the effectiveness of AI-driven simulation workflows and identify potential challenges and limitations.\\n*   **Human-in-the-Loop Simulation:** Explore the optimal ways to incorporate human expertise and feedback into the simulation workflow, creating a collaborative environment where humans and AI agents work together to solve complex problems.\\n*   **Cost-Benefit Analysis:** Conduct a thorough cost-benefit analysis of implementing AI-driven simulation workflows compared to traditional methods, considering factors such as development costs, infrastructure requirements, expert time savings, and improved decision-making.\\n\\nIn essence, the blog post highlights a promising direction for applying AI to simulation. The next stage of research should focus on addressing the practical challenges of integrating this approach into existing workflows, ensuring reliability and trustworthiness, and exploring its full potential across diverse application domains.\\n']\n",
      "Response: dict_keys(['model', 'created_at', 'done', 'done_reason', 'total_duration', 'load_duration', 'prompt_eval_count', 'prompt_eval_duration', 'eval_count', 'eval_duration', 'response', 'context'])\n",
      "Using model: deepseek-r1:1.5b\n",
      "Principal Researcher Approval: Principal Researcher Report\n",
      "\n",
      "<think>\n",
      "Okay, so I'm trying to understand how to apply AI, specifically LLMs like Anthropic's Claude, to simulation workflows. The blog post by the principal is a bit dense, but let me try to break it down.\n",
      "\n",
      "First, I see that simulations are being democratized through LLMs. They're using cloud-based architectures with AWS services, which makes sense because it offers scalability and efficiency. But how exactly do these LLMs act as agents? The blog post talks about the \"Tool Use\" pattern, where the LLM acts as a tool to launch simulations or analyze results. That seems logical because LLMs can understand natural language requests and break them down into actionable steps.\n",
      "\n",
      "I'm a bit confused about how structured chat agents fit in here. They mention using bedrock for multi-input tools, which means each input field is handled by its own tool. This makes sense as it adds modularity to the system. But I wonder if they need to integrate with LLMs or if the LLM can handle multiple inputs on its own.\n",
      "\n",
      "The blog post also mentions structured chat agents supporting Amazon Bedrock, but how does that tie into using Claude V3? Maybe the chat agent handles user interactions before Claude gets into action? That seems plausible because sometimes the first step in a task is just explaining what needs to be done, and then the LLM takes over.\n",
      "\n",
      "I'm thinking about the benefits. By democratizing simulation workflows, businesses can save time and resources by automating routine tasks. This could help reduce inefficiencies caused by manual process repeats or delays from manual intervention. But I'm not sure how this translates into real-world scenarios. For example, healthcare simulations might be too complex for LLMs to handle on their own without human input.\n",
      "\n",
      "Another point is the cloud-based architecture's scalability and efficiency. Using AWS services means it can scale up as needed, but I wonder if that comes with high initial costs or if there are cost-effective strategies. Also, ensuring high availability and fault tolerance might be important for maintaining reliability during simulations.\n",
      "\n",
      "I'm also curious about the structured chat agents. How do they handle multiple inputs? Maybe each input field is sent to a different tool, which then sends back its own instructions. That could create a chain reaction where each step is handled by the right tool based on what's being asked. But I'm not sure how seamless that integration would be compared to having a single LLM.\n",
      "\n",
      "The blog post mentions integrating diverse simulation codes as tools. That sounds powerful because it suggests that different simulation models can work together, like merging two simulations or using code from one source in another. This could lead to more comprehensive and accurate results but might also require careful design to ensure compatibility between the codes.\n",
      "\n",
      "Real-world validation is a key point too. They mention case studies across various industries, which shows the broad applicability of this approach. But how different are these case studies? Do they cover a wide range of simulation scenarios that LLMs would typically encounter in real life? I'm not sure if all industries have common simulation challenges or if it's more niche.\n",
      "\n",
      "Ethical considerations are important as well. They talk about data privacy, bias mitigation, and transparency. I wonder how these are addressed in the implementation. For instance, ensuring that the LLM doesn't perpetuate biases in its training data could be a concern, but maybe with careful data preprocessing and oversight, it can mitigate that.\n",
      "\n",
      "I'm also thinking about the cost-benefit analysis part. The blog post doesn't include numbers, which makes it harder to assess whether the ROI is worth the investment. If I were to implement this, I'd want to know how much it would cost versus how much it could save. But maybe they already did that calculation or provided a recommendation based on potential benefits.\n",
      "\n",
      "Lastly, human-in-the-loop simulation seems like an important aspect. While LLMs are powerful, sometimes they can make errors, especially in complex or ambiguous situations. Incorporating human oversight could improve accuracy and reduce risks. How would this integration happen? Maybe through collaborative filtering where the LLM's predictions are compared against human input to verify their correctness.\n",
      "\n",
      "Overall, it seems like a promising approach, but I'm not sure about all the practical challenges and how each component interacts. I'd need more information on specific implementation details or case studies to fully grasp its potential and limitations.\n",
      "</think>\n",
      "\n",
      "To apply AI, specifically LLMs like Anthropic's Claude V3, to simulation workflows, several key components and considerations are essential:\n",
      "\n",
      "1. **Role of LLMs as Agents**: The blog post highlights the \"Tool Use\" pattern, where LLMs act as tools for launching simulations or analyzing results. This involves breaking down natural language requests into actionable steps, enabling complex problem-solving.\n",
      "\n",
      "2. **Structured Chat Agents**: These agents handle multi-input tasks by sending each input to its own tool, supporting a modular system. Bedrock is mentioned as the foundation for this integration, which could enhance flexibility and efficiency.\n",
      "\n",
      "3. **Real-Time Collaboration**: Structured chat agents may manage multiple inputs on the LLM's side, creating a chain reaction that ensures accurate processing of instructions based on context.\n",
      "\n",
      "4. **Diverse Simulation Codes**: The potential to integrate various simulation codes as tools suggests enhanced comprehensiveness and accuracy by leveraging diverse models or codebases.\n",
      "\n",
      "5. **Real-World Validation**: While case studies across industries are mentioned, specifics regarding the variety and relevance of these cases are unclear. Further research is needed on how widely applicable this approach is in real scenarios.\n",
      "\n",
      "6. **Ethical Considerations**: Addressing biases, ensuring data privacy, and maintaining transparency through robust oversight are critical. These aspects highlight the need for careful implementation to mitigate risks.\n",
      "\n",
      "7. **Cost-Benefit Analysis**: The blog post does not include specific numbers, but a cost-benefit analysis would evaluate ROI vs. investment costs, potentially aiding decision-making on implementation.\n",
      "\n",
      "8. **Human-in-the-Loop**: Enhancing accuracy through collaboration with humans could reduce risks and improve robustness in complex simulations.\n",
      "\n",
      "In conclusion, while this approach presents promising opportunities for democratizing simulation workflows, it requires addressing practical challenges such as integration complexity, scalability, ethical considerations, and cost-benefit analysis to effectively realize its potential. Further exploration into specific implementation details or case studies would provide a clearer understanding of the feasibility and ROI of integrating LLMs with diverse simulation workflows.\n",
      "Response: dict_keys(['candidates', 'create_time', 'response_id', 'model_version', 'prompt_feedback', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])\n",
      "Model: gemini-2.0-flash\n",
      "Usage: cached_content_token_count=None candidates_token_count=1805 prompt_token_count=4454 total_token_count=6259\n",
      "Tech Lead Report: Tech Lead Report\n",
      "\n",
      "Okay, based on the research reviewed, here's a detailed report on agents and agentic workflows, outlining key findings, challenges, and future directions:\n",
      "\n",
      "## Report: Agents and Agentic Workflows: A Deep Dive\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "This report analyzes recent research on agents and agentic workflows, emphasizing the transformative potential of AI-driven automation. Agentic workflows leverage autonomous AI agents, often powered by Large Language Models (LLMs), to dynamically plan, execute, and adapt complex tasks with minimal human intervention. The report highlights key components, challenges, and emerging trends in the field, ultimately suggesting avenues for further investigation and development.  The current research strongly supports that LLMs are effective as orchestrators.\n",
      "\n",
      "**1. Introduction:**\n",
      "\n",
      "The paradigm of automating complex tasks is shifting from rigid, rule-based systems to more flexible and intelligent agentic workflows. An *agent* is defined as an entity capable of perceiving its environment, reasoning, and acting autonomously to achieve specific goals. An *agentic workflow* is a structured process orchestrated by one or more agents working independently or collaboratively. This report examines the core concepts, key research areas, and applications of agentic workflows.\n",
      "\n",
      "**2. Core Concepts and Components:**\n",
      "\n",
      "*   **Agents:** Autonomous entities characterized by reactivity, proactiveness, and, often, social ability.\n",
      "*   **Agentic Workflow:**  A multi-step, iterative process where agents:\n",
      "    *   Decompose complex goals into manageable sub-tasks.\n",
      "    *   Plan and execute actions.\n",
      "    *   Communicate and coordinate (in multi-agent systems).\n",
      "    *   Monitor progress and adapt plans.\n",
      "*   **Large Language Models (LLMs):**  Increasingly used as the core decision-making engine for agents, leveraging their natural language understanding, reasoning, and code generation capabilities.\n",
      "*   **Tools:** External resources, datasets, APIs, or specialized software components that LLMs can access and utilize to augment their capabilities. These extend the agent's knowledge and action space.\n",
      "*   **Prompt Engineering:** The process of crafting effective prompts to guide LLMs in performing specific tasks. Techniques like chain-of-thought prompting and self-reflection are crucial for agentic applications.\n",
      "*   **Feedback Mechanisms:** Human-in-the-loop (HITL) systems or other agents provide guidance and corrections to the AI agent's decision-making.\n",
      "*   **Multi-Agent Systems (MASs):** Multiple agents that can communicate and influence each other, that are essential for the most complex use cases.\n",
      "\n",
      "**3. Key Research Areas and Challenges:**\n",
      "\n",
      "This section details active areas of research and their associated challenges:\n",
      "\n",
      "*   **Agent Architectures:**\n",
      "    *   *Research:* Exploration of different architectural approaches, including symbolic, reactive, hybrid, reinforcement learning, and LLM-based agents.\n",
      "    *   *Challenges:* Scalability to complex environments, explainability of decisions (especially for LLM-based agents), robustness in uncertain environments, adaptability to new situations, and memory management (especially for LLM agents with limited context windows).\n",
      "*   **Planning and Decision-Making:**\n",
      "    *   *Research:*  Development of algorithms for generating plans, making decisions under uncertainty, and coordinating actions in multi-agent scenarios.\n",
      "    *   *Challenges:* Handling uncertainty, computational complexity of planning algorithms, real-time planning in dynamic environments, integrating planning with learning, and equipping agents with common-sense reasoning.\n",
      "*   **Communication and Coordination:**\n",
      "    *   *Research:*  Investigation of how agents can communicate, share information, and coordinate actions to achieve common goals.\n",
      "    *   *Challenges:* Scalability of communication protocols, robustness in noisy environments, trust and security, human-agent interaction, and semantic interoperability between heterogeneous agents.\n",
      "*   **Learning and Adaptation:**\n",
      "    *   *Research:* Development of techniques for agents to learn from experience, adapt to new environments, and improve performance over time, including reinforcement learning, imitation learning, and transfer learning.\n",
      "    *   *Challenges:* Sample efficiency, balancing exploration vs. exploitation, reward shaping, generalization to unseen environments, catastrophic forgetting, and ensuring safety during learning.\n",
      "*   **LLM-Powered Agents:**\n",
      "     *   *Research:* Using Large Language Models (LLMs) for planning, reasoning, and decision-making within agent frameworks, and investigating how to leverage the power of LLMs.\n",
      "     *   *Challenges:* Prompt Engineering for Agents, Tool Use, Memory Management, Agent Orchestration, Fine-tuning LLMs for Agentic Tasks.\n",
      "*   **Ethical Considerations**\n",
      "    *   *Research:*  Understanding the long term safety and ethical considerations of agentic workflows in real-world scenarios.\n",
      "    *   *Challenges:* Bias mitigation, data privacy, explainability, and safety.\n",
      "\n",
      "**4. Applications of Agentic Workflows:**\n",
      "\n",
      "Agentic workflows are being applied to a wide range of domains:\n",
      "\n",
      "*   **Robotics:** Autonomous robots for manufacturing, logistics, and exploration.\n",
      "*   **Smart Environments:** Intelligent systems for managing energy, transportation, and security in homes and cities.\n",
      "*   **Healthcare:** Diagnostic tools, personalized treatment plans, and robotic surgery.\n",
      "*   **Finance:** Algorithmic trading, risk management, and fraud detection.\n",
      "*   **Supply Chain Management:** Optimizing logistics, inventory control, and procurement.\n",
      "*   **Information Retrieval and Filtering:** Personalized search engines, recommender systems, and spam filters.\n",
      "*   **Software Engineering:** Automated testing, code generation, and debugging.\n",
      "*   **Simulation:** Streamline and democratize simulation processes by managing and interacting through prompts.\n",
      "\n",
      "*Challenges:* Integration with existing infrastructure, trust and acceptance by users, ethical considerations, security, and scalability.*\n",
      "\n",
      "**5. Current Trends and Emerging Areas:**\n",
      "\n",
      "*   **LLM-Powered Agents:**  Dominating research efforts, focusing on leveraging LLMs for planning, reasoning, and decision-making. Key areas include prompt engineering, tool use, memory management, and agent orchestration.\n",
      "*   **Human-in-the-Loop Agent Systems:**  Recognizing the need for collaboration between humans and agents, research is focused on explainable AI (XAI), interactive planning, and trust modeling.\n",
      "*   **Agent Swarms and Collective Intelligence:**  Exploring how large numbers of simple agents can collectively solve complex problems through decentralized control, stigmergy, and self-organization.\n",
      "*   **Formal Verification of Agent Systems:** Developing formal methods to verify the correctness, safety, and security of agent systems, particularly for safety-critical applications.\n",
      "*   **Democratization of Simulation:** Using LLMs and agentic workflows to streamline and democratize simulation processes, making them accessible to a wider audience.\n",
      "\n",
      "**6. Future Research Directions:**\n",
      "\n",
      "Based on the analysis, the following areas warrant further research:\n",
      "\n",
      "*   **Integration with Existing Simulation Codebases:** Seamlessly integrating diverse and complex simulation codes as tools within agentic LLM workflows.\n",
      "*   **Simulation Reproducibility and Traceability:** Developing robust logging mechanisms and data provenance tracking for AI-driven simulation workflows.\n",
      "*   **Guardrails and Ethical Considerations:** Establishing appropriate safeguards for the responsible use of AI-driven simulation frameworks.\n",
      "*   **Tool Design and Optimization:** Exploring optimal tool design principles for effective interaction between LLMs and external resources.\n",
      "*   **LLM Fine-Tuning for Agentic Tasks:** Investigating the benefits of fine-tuning LLMs on agentic tasks to improve their performance.\n",
      "*   **Explainable AI (XAI) for Agentic Decision-Making:** Developing techniques to make agent decisions transparent and understandable to humans.\n",
      "*   **Real-World Validation and Case Studies:**  Conducting real-world case studies to validate the effectiveness of agentic workflows across diverse applications.\n",
      "*   **Human-in-the-Loop Simulation:** Explore the optimal ways to incorporate human expertise and feedback into the simulation workflow, creating a collaborative environment where humans and AI agents work together to solve complex problems.\n",
      "*   **Cost-Benefit Analysis:** Conduct a thorough cost-benefit analysis of implementing AI-driven simulation workflows compared to traditional methods.\n",
      "\n",
      "**7. Conclusion:**\n",
      "\n",
      "Agentic workflows represent a paradigm shift in automation, enabling AI agents to handle complex tasks with minimal human intervention. The field is rapidly evolving, driven by advancements in LLMs, agent architectures, and distributed systems.  While significant progress has been made, challenges remain in terms of scalability, explainability, robustness, and ethical considerations. Future research should focus on addressing these challenges and exploring the full potential of agentic workflows across diverse application domains.  A key focus must be the reproducibility, explainability, and safety of the agentic workflow.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:18:45.882782Z",
     "start_time": "2025-03-24T05:18:45.880054Z"
    }
   },
   "cell_type": "code",
   "source": "print(principal_researcher_report)",
   "id": "c9620942277993da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Researcher Report\n",
      "\n",
      "<think>\n",
      "Okay, so I'm trying to understand how to apply AI, specifically LLMs like Anthropic's Claude, to simulation workflows. The blog post by the principal is a bit dense, but let me try to break it down.\n",
      "\n",
      "First, I see that simulations are being democratized through LLMs. They're using cloud-based architectures with AWS services, which makes sense because it offers scalability and efficiency. But how exactly do these LLMs act as agents? The blog post talks about the \"Tool Use\" pattern, where the LLM acts as a tool to launch simulations or analyze results. That seems logical because LLMs can understand natural language requests and break them down into actionable steps.\n",
      "\n",
      "I'm a bit confused about how structured chat agents fit in here. They mention using bedrock for multi-input tools, which means each input field is handled by its own tool. This makes sense as it adds modularity to the system. But I wonder if they need to integrate with LLMs or if the LLM can handle multiple inputs on its own.\n",
      "\n",
      "The blog post also mentions structured chat agents supporting Amazon Bedrock, but how does that tie into using Claude V3? Maybe the chat agent handles user interactions before Claude gets into action? That seems plausible because sometimes the first step in a task is just explaining what needs to be done, and then the LLM takes over.\n",
      "\n",
      "I'm thinking about the benefits. By democratizing simulation workflows, businesses can save time and resources by automating routine tasks. This could help reduce inefficiencies caused by manual process repeats or delays from manual intervention. But I'm not sure how this translates into real-world scenarios. For example, healthcare simulations might be too complex for LLMs to handle on their own without human input.\n",
      "\n",
      "Another point is the cloud-based architecture's scalability and efficiency. Using AWS services means it can scale up as needed, but I wonder if that comes with high initial costs or if there are cost-effective strategies. Also, ensuring high availability and fault tolerance might be important for maintaining reliability during simulations.\n",
      "\n",
      "I'm also curious about the structured chat agents. How do they handle multiple inputs? Maybe each input field is sent to a different tool, which then sends back its own instructions. That could create a chain reaction where each step is handled by the right tool based on what's being asked. But I'm not sure how seamless that integration would be compared to having a single LLM.\n",
      "\n",
      "The blog post mentions integrating diverse simulation codes as tools. That sounds powerful because it suggests that different simulation models can work together, like merging two simulations or using code from one source in another. This could lead to more comprehensive and accurate results but might also require careful design to ensure compatibility between the codes.\n",
      "\n",
      "Real-world validation is a key point too. They mention case studies across various industries, which shows the broad applicability of this approach. But how different are these case studies? Do they cover a wide range of simulation scenarios that LLMs would typically encounter in real life? I'm not sure if all industries have common simulation challenges or if it's more niche.\n",
      "\n",
      "Ethical considerations are important as well. They talk about data privacy, bias mitigation, and transparency. I wonder how these are addressed in the implementation. For instance, ensuring that the LLM doesn't perpetuate biases in its training data could be a concern, but maybe with careful data preprocessing and oversight, it can mitigate that.\n",
      "\n",
      "I'm also thinking about the cost-benefit analysis part. The blog post doesn't include numbers, which makes it harder to assess whether the ROI is worth the investment. If I were to implement this, I'd want to know how much it would cost versus how much it could save. But maybe they already did that calculation or provided a recommendation based on potential benefits.\n",
      "\n",
      "Lastly, human-in-the-loop simulation seems like an important aspect. While LLMs are powerful, sometimes they can make errors, especially in complex or ambiguous situations. Incorporating human oversight could improve accuracy and reduce risks. How would this integration happen? Maybe through collaborative filtering where the LLM's predictions are compared against human input to verify their correctness.\n",
      "\n",
      "Overall, it seems like a promising approach, but I'm not sure about all the practical challenges and how each component interacts. I'd need more information on specific implementation details or case studies to fully grasp its potential and limitations.\n",
      "</think>\n",
      "\n",
      "To apply AI, specifically LLMs like Anthropic's Claude V3, to simulation workflows, several key components and considerations are essential:\n",
      "\n",
      "1. **Role of LLMs as Agents**: The blog post highlights the \"Tool Use\" pattern, where LLMs act as tools for launching simulations or analyzing results. This involves breaking down natural language requests into actionable steps, enabling complex problem-solving.\n",
      "\n",
      "2. **Structured Chat Agents**: These agents handle multi-input tasks by sending each input to its own tool, supporting a modular system. Bedrock is mentioned as the foundation for this integration, which could enhance flexibility and efficiency.\n",
      "\n",
      "3. **Real-Time Collaboration**: Structured chat agents may manage multiple inputs on the LLM's side, creating a chain reaction that ensures accurate processing of instructions based on context.\n",
      "\n",
      "4. **Diverse Simulation Codes**: The potential to integrate various simulation codes as tools suggests enhanced comprehensiveness and accuracy by leveraging diverse models or codebases.\n",
      "\n",
      "5. **Real-World Validation**: While case studies across industries are mentioned, specifics regarding the variety and relevance of these cases are unclear. Further research is needed on how widely applicable this approach is in real scenarios.\n",
      "\n",
      "6. **Ethical Considerations**: Addressing biases, ensuring data privacy, and maintaining transparency through robust oversight are critical. These aspects highlight the need for careful implementation to mitigate risks.\n",
      "\n",
      "7. **Cost-Benefit Analysis**: The blog post does not include specific numbers, but a cost-benefit analysis would evaluate ROI vs. investment costs, potentially aiding decision-making on implementation.\n",
      "\n",
      "8. **Human-in-the-Loop**: Enhancing accuracy through collaboration with humans could reduce risks and improve robustness in complex simulations.\n",
      "\n",
      "In conclusion, while this approach presents promising opportunities for democratizing simulation workflows, it requires addressing practical challenges such as integration complexity, scalability, ethical considerations, and cost-benefit analysis to effectively realize its potential. Further exploration into specific implementation details or case studies would provide a clearer understanding of the feasibility and ROI of integrating LLMs with diverse simulation workflows.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:18:45.931329Z",
     "start_time": "2025-03-24T05:18:45.927601Z"
    }
   },
   "cell_type": "code",
   "source": "print(tech_lead_report)",
   "id": "d4042f03e9d267b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tech Lead Report\n",
      "\n",
      "Okay, based on the research reviewed, here's a detailed report on agents and agentic workflows, outlining key findings, challenges, and future directions:\n",
      "\n",
      "## Report: Agents and Agentic Workflows: A Deep Dive\n",
      "\n",
      "**Executive Summary:**\n",
      "\n",
      "This report analyzes recent research on agents and agentic workflows, emphasizing the transformative potential of AI-driven automation. Agentic workflows leverage autonomous AI agents, often powered by Large Language Models (LLMs), to dynamically plan, execute, and adapt complex tasks with minimal human intervention. The report highlights key components, challenges, and emerging trends in the field, ultimately suggesting avenues for further investigation and development.  The current research strongly supports that LLMs are effective as orchestrators.\n",
      "\n",
      "**1. Introduction:**\n",
      "\n",
      "The paradigm of automating complex tasks is shifting from rigid, rule-based systems to more flexible and intelligent agentic workflows. An *agent* is defined as an entity capable of perceiving its environment, reasoning, and acting autonomously to achieve specific goals. An *agentic workflow* is a structured process orchestrated by one or more agents working independently or collaboratively. This report examines the core concepts, key research areas, and applications of agentic workflows.\n",
      "\n",
      "**2. Core Concepts and Components:**\n",
      "\n",
      "*   **Agents:** Autonomous entities characterized by reactivity, proactiveness, and, often, social ability.\n",
      "*   **Agentic Workflow:**  A multi-step, iterative process where agents:\n",
      "    *   Decompose complex goals into manageable sub-tasks.\n",
      "    *   Plan and execute actions.\n",
      "    *   Communicate and coordinate (in multi-agent systems).\n",
      "    *   Monitor progress and adapt plans.\n",
      "*   **Large Language Models (LLMs):**  Increasingly used as the core decision-making engine for agents, leveraging their natural language understanding, reasoning, and code generation capabilities.\n",
      "*   **Tools:** External resources, datasets, APIs, or specialized software components that LLMs can access and utilize to augment their capabilities. These extend the agent's knowledge and action space.\n",
      "*   **Prompt Engineering:** The process of crafting effective prompts to guide LLMs in performing specific tasks. Techniques like chain-of-thought prompting and self-reflection are crucial for agentic applications.\n",
      "*   **Feedback Mechanisms:** Human-in-the-loop (HITL) systems or other agents provide guidance and corrections to the AI agent's decision-making.\n",
      "*   **Multi-Agent Systems (MASs):** Multiple agents that can communicate and influence each other, that are essential for the most complex use cases.\n",
      "\n",
      "**3. Key Research Areas and Challenges:**\n",
      "\n",
      "This section details active areas of research and their associated challenges:\n",
      "\n",
      "*   **Agent Architectures:**\n",
      "    *   *Research:* Exploration of different architectural approaches, including symbolic, reactive, hybrid, reinforcement learning, and LLM-based agents.\n",
      "    *   *Challenges:* Scalability to complex environments, explainability of decisions (especially for LLM-based agents), robustness in uncertain environments, adaptability to new situations, and memory management (especially for LLM agents with limited context windows).\n",
      "*   **Planning and Decision-Making:**\n",
      "    *   *Research:*  Development of algorithms for generating plans, making decisions under uncertainty, and coordinating actions in multi-agent scenarios.\n",
      "    *   *Challenges:* Handling uncertainty, computational complexity of planning algorithms, real-time planning in dynamic environments, integrating planning with learning, and equipping agents with common-sense reasoning.\n",
      "*   **Communication and Coordination:**\n",
      "    *   *Research:*  Investigation of how agents can communicate, share information, and coordinate actions to achieve common goals.\n",
      "    *   *Challenges:* Scalability of communication protocols, robustness in noisy environments, trust and security, human-agent interaction, and semantic interoperability between heterogeneous agents.\n",
      "*   **Learning and Adaptation:**\n",
      "    *   *Research:* Development of techniques for agents to learn from experience, adapt to new environments, and improve performance over time, including reinforcement learning, imitation learning, and transfer learning.\n",
      "    *   *Challenges:* Sample efficiency, balancing exploration vs. exploitation, reward shaping, generalization to unseen environments, catastrophic forgetting, and ensuring safety during learning.\n",
      "*   **LLM-Powered Agents:**\n",
      "     *   *Research:* Using Large Language Models (LLMs) for planning, reasoning, and decision-making within agent frameworks, and investigating how to leverage the power of LLMs.\n",
      "     *   *Challenges:* Prompt Engineering for Agents, Tool Use, Memory Management, Agent Orchestration, Fine-tuning LLMs for Agentic Tasks.\n",
      "*   **Ethical Considerations**\n",
      "    *   *Research:*  Understanding the long term safety and ethical considerations of agentic workflows in real-world scenarios.\n",
      "    *   *Challenges:* Bias mitigation, data privacy, explainability, and safety.\n",
      "\n",
      "**4. Applications of Agentic Workflows:**\n",
      "\n",
      "Agentic workflows are being applied to a wide range of domains:\n",
      "\n",
      "*   **Robotics:** Autonomous robots for manufacturing, logistics, and exploration.\n",
      "*   **Smart Environments:** Intelligent systems for managing energy, transportation, and security in homes and cities.\n",
      "*   **Healthcare:** Diagnostic tools, personalized treatment plans, and robotic surgery.\n",
      "*   **Finance:** Algorithmic trading, risk management, and fraud detection.\n",
      "*   **Supply Chain Management:** Optimizing logistics, inventory control, and procurement.\n",
      "*   **Information Retrieval and Filtering:** Personalized search engines, recommender systems, and spam filters.\n",
      "*   **Software Engineering:** Automated testing, code generation, and debugging.\n",
      "*   **Simulation:** Streamline and democratize simulation processes by managing and interacting through prompts.\n",
      "\n",
      "*Challenges:* Integration with existing infrastructure, trust and acceptance by users, ethical considerations, security, and scalability.*\n",
      "\n",
      "**5. Current Trends and Emerging Areas:**\n",
      "\n",
      "*   **LLM-Powered Agents:**  Dominating research efforts, focusing on leveraging LLMs for planning, reasoning, and decision-making. Key areas include prompt engineering, tool use, memory management, and agent orchestration.\n",
      "*   **Human-in-the-Loop Agent Systems:**  Recognizing the need for collaboration between humans and agents, research is focused on explainable AI (XAI), interactive planning, and trust modeling.\n",
      "*   **Agent Swarms and Collective Intelligence:**  Exploring how large numbers of simple agents can collectively solve complex problems through decentralized control, stigmergy, and self-organization.\n",
      "*   **Formal Verification of Agent Systems:** Developing formal methods to verify the correctness, safety, and security of agent systems, particularly for safety-critical applications.\n",
      "*   **Democratization of Simulation:** Using LLMs and agentic workflows to streamline and democratize simulation processes, making them accessible to a wider audience.\n",
      "\n",
      "**6. Future Research Directions:**\n",
      "\n",
      "Based on the analysis, the following areas warrant further research:\n",
      "\n",
      "*   **Integration with Existing Simulation Codebases:** Seamlessly integrating diverse and complex simulation codes as tools within agentic LLM workflows.\n",
      "*   **Simulation Reproducibility and Traceability:** Developing robust logging mechanisms and data provenance tracking for AI-driven simulation workflows.\n",
      "*   **Guardrails and Ethical Considerations:** Establishing appropriate safeguards for the responsible use of AI-driven simulation frameworks.\n",
      "*   **Tool Design and Optimization:** Exploring optimal tool design principles for effective interaction between LLMs and external resources.\n",
      "*   **LLM Fine-Tuning for Agentic Tasks:** Investigating the benefits of fine-tuning LLMs on agentic tasks to improve their performance.\n",
      "*   **Explainable AI (XAI) for Agentic Decision-Making:** Developing techniques to make agent decisions transparent and understandable to humans.\n",
      "*   **Real-World Validation and Case Studies:**  Conducting real-world case studies to validate the effectiveness of agentic workflows across diverse applications.\n",
      "*   **Human-in-the-Loop Simulation:** Explore the optimal ways to incorporate human expertise and feedback into the simulation workflow, creating a collaborative environment where humans and AI agents work together to solve complex problems.\n",
      "*   **Cost-Benefit Analysis:** Conduct a thorough cost-benefit analysis of implementing AI-driven simulation workflows compared to traditional methods.\n",
      "\n",
      "**7. Conclusion:**\n",
      "\n",
      "Agentic workflows represent a paradigm shift in automation, enabling AI agents to handle complex tasks with minimal human intervention. The field is rapidly evolving, driven by advancements in LLMs, agent architectures, and distributed systems.  While significant progress has been made, challenges remain in terms of scalability, explainability, robustness, and ethical considerations. Future research should focus on addressing these challenges and exploring the full potential of agentic workflows across diverse application domains.  A key focus must be the reproducibility, explainability, and safety of the agentic workflow.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T05:18:45.981790Z",
     "start_time": "2025-03-24T05:18:45.978892Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b9fe11d2ab3ea5c4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
