{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "1f333b39305f146a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:03:46.411782Z",
     "start_time": "2025-03-23T17:03:45.585490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from saw.workflows.adaptive_llm.adaptive import adaptive, aadaptive"
   ],
   "id": "275268ee0eaac320",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:03:46.419397Z",
     "start_time": "2025-03-23T17:03:46.415195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load environment variables\n",
    "load_dotenv(\"../docker/.env\")"
   ],
   "id": "80284852cc249774",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Variables",
   "id": "64356d3cd693f4a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:03:46.476460Z",
     "start_time": "2025-03-23T17:03:46.474397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_prompt = \"You are a helpful assistant.\"\n",
    "provider = \"google\"\n",
    "model = \"gemini-2.0-flash\"\n",
    "provider2 = \"ollama\"\n",
    "model2 = \"deepseek-r1:1.5b\"\n",
    "provider3 = \"groq\"\n",
    "model3 = \"llama3-8b-8192\"\n",
    "provider4 = \"openai\"\n",
    "model4 = \"gpt-4o-mini\""
   ],
   "id": "279adbb49b6415ec",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T17:03:46.521356Z",
     "start_time": "2025-03-23T17:03:46.518348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "evaluator_prompt_details = {\n",
    "    \"prompt\": \"\"\"\n",
    "    Evaluate the following code implementation for:\n",
    "    1. code correctness\n",
    "    2. efficiency\n",
    "    3. adherence to design patterns\n",
    "    4. pep8 compliance\n",
    "    \"\"\",\n",
    "    \"model\": model,\n",
    "    \"provider\": provider,\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"functions\": [str.lower]  # Example function to lower case the prompt\n",
    "}\n",
    "\n",
    "generator_prompt_details = {\n",
    "    \"prompt\": \"\"\"\n",
    "    Your goal is to complete the task based on the context and provide feedback on how you \\\n",
    "    should reflect on them to improve your solution.\n",
    "    \"\"\",\n",
    "    \"model\": model,\n",
    "    \"provider\": provider,\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"functions\": [str.lower]\n",
    "}\n",
    "\n",
    "ratings = [\"PASS\", \"NEEDS_IMPROVEMENT\", \"FAIL\"]\n",
    "\n",
    "task = \"\"\"\n",
    "Implement a Queue with:\n",
    "1. enqueue(x)\n",
    "2. dequeue()\n",
    "3. getFront()\n",
    "All operations should be O(1).\n",
    "\"\"\""
   ],
   "id": "ea95097f626aee80",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Synchronous Loop Example\n",
    "The `adaptive` function allows us to keep generating and evaluating until the requirements are met."
   ],
   "id": "2e40cd1bf20a578"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result, chain_of_thought = adaptive(evaluator_prompt_details=evaluator_prompt_details,\n",
    "                                    generator_prompt_details=generator_prompt_details,\n",
    "                                    ratings=ratings,\n",
    "                                    task=task, max_iterations=2)\n",
    "print(f\"Final Result:\\n{result}\")\n",
    "print(f\"Chain of Thought:\\n{chain_of_thought}\")"
   ],
   "id": "2d75f4c188d0bb2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Asynchronous Loop Example\n",
    "We can also use the asynchronous version of the `adaptive` function."
   ],
   "id": "ded24e090d2a77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Asynchronous Loop Started...\")\n",
    "async_result, async_chain_of_thought = await aadaptive(\n",
    "    evaluator_prompt_details=evaluator_prompt_details, generator_prompt_details=generator_prompt_details,\n",
    "    ratings=ratings, task=task, max_iterations=3\n",
    ")\n",
    "\n",
    "print(f\"Asynchronous Final Result:\\n{async_result}\")\n",
    "print(f\"Asynchronous Chain of Thought:\\n{async_chain_of_thought}\")"
   ],
   "id": "5c4aea02d23fae33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a3719dc44e7967f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
